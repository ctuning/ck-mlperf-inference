[
  {
    "50.00 percentile latency (ns)": 205736318,
    "90.00 percentile latency (ns)": 372365251,
    "90th percentile latency (ns)": 372365251,
    "95.00 percentile latency (ns)": 436602273,
    "97.00 percentile latency (ns)": 465118922,
    "99.00 percentile latency (ns)": 487812534,
    "99.90 percentile latency (ns)": 543402259,
    "Max latency (ns)": 572448603,
    "Mean latency (ns)": 225495027,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 55504372,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 4.39,
    "QPS w/o loadgen overhead": 4.43,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 372.365251,
    "characteristics.90th_percentile_latency_ns": 372365251.0,
    "characteristics.90th_percentile_latency_s": 0.372365251,
    "characteristics.90th_percentile_latency_us": 372365.251,
    "characteristics.accuracy": 92.56127533879005,
    "characteristics.power": 3.4472117815895573,
    "characteristics.power.normalized_per_core": 3.4472117815895573,
    "characteristics.power.normalized_per_processor": 3.4472117815895573,
    "characteristics.word error rate": 7.438724661209949,
    "ck_system": "Xavier_NX_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "8 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 6,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "Micro SD Card",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Xavier_NX_TRT_MaxQ",
    "system_name": "NVIDIA Jetson Xavier NX (MaxQ, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 5,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 6,
    "uid": "dd34350bb57e0e2e",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 93492049,
    "90.00 percentile latency (ns)": 175169020,
    "90th percentile latency (ns)": 175169020,
    "95.00 percentile latency (ns)": 197610402,
    "97.00 percentile latency (ns)": 214398246,
    "99.00 percentile latency (ns)": 227837710,
    "99.90 percentile latency (ns)": 237153897,
    "Max latency (ns)": 239006258,
    "Mean latency (ns)": 103733156,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 26790134,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 9.64,
    "QPS w/o loadgen overhead": 9.64,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA AGX Xavier",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 175.16902,
    "characteristics.90th_percentile_latency_ns": 175169020.0,
    "characteristics.90th_percentile_latency_s": 0.17516902,
    "characteristics.90th_percentile_latency_us": 175169.02,
    "characteristics.accuracy": 92.56353018106384,
    "characteristics.word error rate": 7.436469818936166,
    "ck_system": "AGX_Xavier_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "32 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 8,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "eMMC 5.1",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/AGX_Xavier_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/AGX_Xavier_TRT",
    "system_name": "NVIDIA Jetson AGX Xavier 32GB (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 10,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 8,
    "uid": "6be4d5b855c34775",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 12619551,
    "90.00 percentile latency (ns)": 22585203,
    "90th percentile latency (ns)": 22585203,
    "95.00 percentile latency (ns)": 25284848,
    "97.00 percentile latency (ns)": 26783502,
    "99.00 percentile latency (ns)": 28574302,
    "99.90 percentile latency (ns)": 30673801,
    "Max latency (ns)": 33933573,
    "Mean latency (ns)": 14046728,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 3922076,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 71.11,
    "QPS w/o loadgen overhead": 71.19,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 22.585203,
    "characteristics.90th_percentile_latency_ns": 22585203.0,
    "characteristics.90th_percentile_latency_s": 0.022585203,
    "characteristics.90th_percentile_latency_us": 22585.203,
    "characteristics.accuracy": 92.57029470788518,
    "characteristics.word error rate": 7.429705292114816,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_edge",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_edge",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_edge",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "12ace358345879be",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 183678973,
    "90.00 percentile latency (ns)": 330518287,
    "90th percentile latency (ns)": 330518287,
    "95.00 percentile latency (ns)": 384047705,
    "97.00 percentile latency (ns)": 412129306,
    "99.00 percentile latency (ns)": 439303426,
    "99.90 percentile latency (ns)": 456752788,
    "Max latency (ns)": 467788616,
    "Mean latency (ns)": 199536070,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 50514566,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 4.96,
    "QPS w/o loadgen overhead": 5.01,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA AGX Xavier",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 330.518287,
    "characteristics.90th_percentile_latency_ns": 330518287.0,
    "characteristics.90th_percentile_latency_s": 0.330518287,
    "characteristics.90th_percentile_latency_us": 330518.287,
    "characteristics.accuracy": 92.55902049651627,
    "characteristics.power": 4.115906912985686,
    "characteristics.power.normalized_per_core": 4.115906912985686,
    "characteristics.power.normalized_per_processor": 4.115906912985686,
    "characteristics.word error rate": 7.440979503483732,
    "ck_system": "AGX_Xavier_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "32 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 8,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "eMMC 5.1",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/AGX_Xavier_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/AGX_Xavier_TRT_MaxQ",
    "system_name": "NVIDIA Jetson AGX Xavier 32GB (MaxQ, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 10,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 8,
    "uid": "f89be69571377c2e",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 71369356,
    "90.00 percentile latency (ns)": 135936783,
    "90th percentile latency (ns)": 135936783,
    "95.00 percentile latency (ns)": 152978801,
    "97.00 percentile latency (ns)": 165936458,
    "99.00 percentile latency (ns)": 177065041,
    "99.90 percentile latency (ns)": 183130543,
    "Max latency (ns)": 187707370,
    "Mean latency (ns)": 79692865,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 20248731,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 12.54,
    "QPS w/o loadgen overhead": 12.55,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30 (1x1g.3gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 135.936783,
    "characteristics.90th_percentile_latency_ns": 135936783.0,
    "characteristics.90th_percentile_latency_s": 0.135936783,
    "characteristics.90th_percentile_latency_us": 135936.783,
    "characteristics.accuracy": 92.56578502333763,
    "characteristics.word error rate": 7.434214976662383,
    "ck_system": "A30-MIG_1x1g.3gb_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.3gb_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30-MIG_1x1g.3gb_TRT",
    "system_name": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.3gb, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 134.177,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "484eb269b42a0bb6",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 22093940,
    "90.00 percentile latency (ns)": 39826042,
    "90th percentile latency (ns)": 39826042,
    "95.00 percentile latency (ns)": 44810874,
    "97.00 percentile latency (ns)": 48337623,
    "99.00 percentile latency (ns)": 51719191,
    "99.90 percentile latency (ns)": 55268405,
    "Max latency (ns)": 59537675,
    "Mean latency (ns)": 24327987,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 7020150,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 41.01,
    "QPS w/o loadgen overhead": 41.1,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 39.826042,
    "characteristics.90th_percentile_latency_ns": 39826042.0,
    "characteristics.90th_percentile_latency_s": 0.039826042,
    "characteristics.90th_percentile_latency_us": 39826.042,
    "characteristics.accuracy": 92.57029470788518,
    "characteristics.word error rate": 7.429705292114816,
    "ck_system": "A10x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x1_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x1_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (1x A10, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 40,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 56,
    "uid": "4dbe5ec9202343ce",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 14772224,
    "90.00 percentile latency (ns)": 26336180,
    "90th percentile latency (ns)": 26336180,
    "95.00 percentile latency (ns)": 29633924,
    "97.00 percentile latency (ns)": 31391632,
    "99.00 percentile latency (ns)": 34021874,
    "99.90 percentile latency (ns)": 38780430,
    "Max latency (ns)": 44465492,
    "Mean latency (ns)": 16341327,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4719475,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 61.03,
    "QPS w/o loadgen overhead": 61.19,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 26.33618,
    "characteristics.90th_percentile_latency_ns": 26336180.0,
    "characteristics.90th_percentile_latency_s": 0.02633618,
    "characteristics.90th_percentile_latency_us": 26336.18,
    "characteristics.accuracy": 92.5680398656114,
    "characteristics.word error rate": 7.4319601343886,
    "ck_system": "A30x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x1_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x1_TRT",
    "system_name": "Gigabyte G482-Z54 (1x A30, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "46ea20e95df94ccf",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 40368097,
    "90.00 percentile latency (ns)": 76311397,
    "90th percentile latency (ns)": 76311397,
    "95.00 percentile latency (ns)": 85541415,
    "97.00 percentile latency (ns)": 92900504,
    "99.00 percentile latency (ns)": 98647772,
    "99.90 percentile latency (ns)": 102828732,
    "Max latency (ns)": 106027470,
    "Mean latency (ns)": 45109290,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 11910775,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 22.17,
    "QPS w/o loadgen overhead": 22.17,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 76.311397,
    "characteristics.90th_percentile_latency_ns": 76311397.0,
    "characteristics.90th_percentile_latency_s": 0.076311397,
    "characteristics.90th_percentile_latency_us": 76311.397,
    "characteristics.accuracy": 92.56578502333763,
    "characteristics.word error rate": 7.434214976662383,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "94bf4364a674f6d8",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 13296986,
    "90.00 percentile latency (ns)": 24047584,
    "90th percentile latency (ns)": 24047584,
    "95.00 percentile latency (ns)": 26951320,
    "97.00 percentile latency (ns)": 28597038,
    "99.00 percentile latency (ns)": 31478014,
    "99.90 percentile latency (ns)": 36803612,
    "Max latency (ns)": 53318744,
    "Mean latency (ns)": 14886323,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4182668,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 66.86,
    "QPS w/o loadgen overhead": 67.18,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 24.047584,
    "characteristics.90th_percentile_latency_ns": 24047584.0,
    "characteristics.90th_percentile_latency_s": 0.024047584,
    "characteristics.90th_percentile_latency_us": 24047.584,
    "characteristics.accuracy": 92.57029470788518,
    "characteristics.word error rate": 7.429705292114816,
    "ck_system": "A100-PCIex1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex1_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex1_TRT",
    "system_name": "Gigabyte G482-Z54 (1x A100-PCIe, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "70b316bce4fc4121",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 200611130,
    "90.00 percentile latency (ns)": 361863308,
    "90th percentile latency (ns)": 361863308,
    "95.00 percentile latency (ns)": 420574112,
    "97.00 percentile latency (ns)": 450430366,
    "99.00 percentile latency (ns)": 474047162,
    "99.90 percentile latency (ns)": 500308662,
    "Max latency (ns)": 506231188,
    "Mean latency (ns)": 218499688,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 58614252,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 4.53,
    "QPS w/o loadgen overhead": 4.58,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 361.863308,
    "characteristics.90th_percentile_latency_ns": 361863308.0,
    "characteristics.90th_percentile_latency_s": 0.361863308,
    "characteristics.90th_percentile_latency_us": 361863.308,
    "characteristics.accuracy": 92.56127533879005,
    "characteristics.word error rate": 7.438724661209949,
    "ck_system": "Xavier_NX_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "8 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 6,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "Micro SD Card",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 2513,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Xavier_NX_TRT",
    "system_name": "NVIDIA Jetson Xavier NX (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 5,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 6,
    "uid": "7c141dead44df9e2",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 15054522,
    "90.00 percentile latency (ns)": 27375305,
    "90th percentile latency (ns)": 27375305,
    "95.00 percentile latency (ns)": 30836949,
    "97.00 percentile latency (ns)": 32730682,
    "99.00 percentile latency (ns)": 34875846,
    "99.90 percentile latency (ns)": 38882182,
    "Max latency (ns)": 39627220,
    "Mean latency (ns)": 16889092,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4401437,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 59.17,
    "QPS w/o loadgen overhead": 59.21,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 27.375305,
    "characteristics.90th_percentile_latency_ns": 27375305.0,
    "characteristics.90th_percentile_latency_s": 0.027375305,
    "characteristics.90th_percentile_latency_us": 27375.305,
    "characteristics.accuracy": 92.5680398656114,
    "characteristics.word error rate": 7.4319601343886,
    "ck_system": "DGX-A100_A100-SXM4x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x1_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 2513,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x1_TRT",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM4, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "75ce4321b1f07bb6",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 99034294,
    "90.00 percentile latency (ns)": 179312276,
    "90th percentile latency (ns)": 179312276,
    "95.00 percentile latency (ns)": 202853460,
    "97.00 percentile latency (ns)": 222604980,
    "99.00 percentile latency (ns)": 234505800,
    "99.90 percentile latency (ns)": 241707501,
    "Max latency (ns)": 242492094,
    "Mean latency (ns)": 108361371,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 30502998,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 9.22,
    "QPS w/o loadgen overhead": 9.23,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA AGX Xavier",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 179.312276,
    "characteristics.90th_percentile_latency_ns": 179312276.0,
    "characteristics.90th_percentile_latency_s": 0.179312276,
    "characteristics.90th_percentile_latency_us": 179312.276,
    "characteristics.accuracy": 92.56127533879005,
    "characteristics.word error rate": 7.438724661209949,
    "ck_system": "AGX_Xavier_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2",
    "host_memory_capacity": "32GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 8,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32GB",
    "host_storage_type": "eMMC 5.1",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/AGX_Xavier_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 2513,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/AGX_Xavier_TRT",
    "system_name": "NVIDIA Jetson AGX Xavier 32GB (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 10,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 8,
    "uid": "56bbdeffe86cfb55",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 52329158,
    "90.00 percentile latency (ns)": 95380884,
    "90th percentile latency (ns)": 95380884,
    "95.00 percentile latency (ns)": 106417213,
    "97.00 percentile latency (ns)": 118218387,
    "99.00 percentile latency (ns)": 123288837,
    "99.90 percentile latency (ns)": 128356541,
    "Max latency (ns)": 130048475,
    "Mean latency (ns)": 57231505,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 15771460,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 17.48,
    "QPS w/o loadgen overhead": 17.47,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "5GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4 (1x1g.5gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 95.380884,
    "characteristics.90th_percentile_latency_ns": 95380884.0,
    "characteristics.90th_percentile_latency_s": 0.095380884,
    "characteristics.90th_percentile_latency_us": 95380.884,
    "characteristics.accuracy": 92.56578502333763,
    "characteristics.word error rate": 7.434214976662383,
    "ck_system": "DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 2513,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM4-MIG-1x1g.5gb, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "d6b7103e745a083b",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 35082869,
    "90.00 percentile latency (ns)": 62724225,
    "90th percentile latency (ns)": 62724225,
    "95.00 percentile latency (ns)": 69946256,
    "97.00 percentile latency (ns)": 76602106,
    "99.00 percentile latency (ns)": 81935128,
    "99.90 percentile latency (ns)": 88316954,
    "Max latency (ns)": 89971638,
    "Mean latency (ns)": 38523128,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 12177835,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 25.92,
    "QPS w/o loadgen overhead": 25.96,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 62.724225,
    "characteristics.90th_percentile_latency_ns": 62724225.0,
    "characteristics.90th_percentile_latency_s": 0.062724225,
    "characteristics.90th_percentile_latency_us": 62724.225,
    "characteristics.accuracy": 92.56578502333763,
    "characteristics.word error rate": 7.434214976662383,
    "ck_system": "T4x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x1_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 2513,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x1_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (1x T4, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 40,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 56,
    "uid": "22bdfc1ec6444ceb",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 16553239,
    "90.00 percentile latency (ns)": 31468586,
    "90th percentile latency (ns)": 31468586,
    "95.00 percentile latency (ns)": 35506097,
    "97.00 percentile latency (ns)": 37434245,
    "99.00 percentile latency (ns)": 40624791,
    "99.90 percentile latency (ns)": 44637082,
    "Max latency (ns)": 45293771,
    "Mean latency (ns)": 18758585,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4714500,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 53.17,
    "QPS w/o loadgen overhead": 53.31,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 31.468586,
    "characteristics.90th_percentile_latency_ns": 31468586.0,
    "characteristics.90th_percentile_latency_s": 0.031468586,
    "characteristics.90th_percentile_latency_us": 31468.586,
    "characteristics.accuracy": 92.5680398656114,
    "characteristics.word error rate": 7.4319601343886,
    "ck_system": "A100-PCIex1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex1_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 2513,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex1_TRT",
    "system_name": "Gigabyte G482-Z52 (1x A100-PCIe, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 100,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 128,
    "uid": "d2058b7404788176",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 209864120,
    "90.00 percentile latency (ns)": 375597610,
    "90th percentile latency (ns)": 375597610,
    "95.00 percentile latency (ns)": 433563596,
    "97.00 percentile latency (ns)": 468024745,
    "99.00 percentile latency (ns)": 498463899,
    "99.90 percentile latency (ns)": 517955882,
    "Max latency (ns)": 533321956,
    "Mean latency (ns)": 226916135,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 65890118,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 4.36,
    "QPS w/o loadgen overhead": 4.41,
    "Result is": "VALID",
    "SUT name": "RNNT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 375.59761,
    "characteristics.90th_percentile_latency_ns": 375597610.0,
    "characteristics.90th_percentile_latency_s": 0.37559761,
    "characteristics.90th_percentile_latency_us": 375597.61,
    "characteristics.accuracy": 92.5567656542425,
    "characteristics.word error rate": 7.4432343457575145,
    "ck_system": "Xavier_NX_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "LibriSpeech",
    "dataset_link": "",
    "dim_x_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_default": "characteristics.accuracy",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "rnn-t",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2",
    "host_memory_capacity": "8GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 6,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32GB",
    "host_storage_type": "Micro SD Card",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "rnnt",
    "input_data_types": "fp16",
    "key.accuracy": "characteristics.accuracy",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/Xavier_NX_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 2513,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "DistributedDataParallel_1576581068.9962234-epoch-100.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Xavier_NX_TRT",
    "system_name": "NVIDIA Jetson Xavier NX (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 5,
    "task": "speech recognition",
    "task2": "speech recognition",
    "total_cores": 6,
    "uid": "86a4404da2a4393d",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  }
]
