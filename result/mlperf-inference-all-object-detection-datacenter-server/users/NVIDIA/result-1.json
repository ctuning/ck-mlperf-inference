[
  {
    "50.00 percentile latency (ns)": 7089802,
    "90.00 percentile latency (ns)": 7500769,
    "95.00 percentile latency (ns)": 7582995,
    "97.00 percentile latency (ns)": 7632860,
    "99.00 percentile latency (ns)": 7726985,
    "99.90 percentile latency (ns)": 7987822,
    "Completed samples per second": 81998.26,
    "Max latency (ns)": 13611825,
    "Mean latency (ns)": 7095403,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 6332549,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 82007.78,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA TITAN RTX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "characteristics.mAP": 22.911,
    "characteristics.scheduled_queries_per_second": 82007.78,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 20501.945,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 20501.945,
    "ck_system": "TitanRTXx4",
    "ck_used": false,
    "cooling": "watercooled",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3, libjemalloc2, cub 1.8.0, tensorrt-laboratory mlperf branch",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 24,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) 8268",
    "host_processors_per_node": 2,
    "host_storage_capacity": "3.84 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-small",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.5",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/results/TitanRTXx4",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.3",
    "other_software_stack": "docker 18.09.2, python 3.6.8,gcc 5.5.0,onnx 1.3.0, tensorflow 1.13.1, pytorch 1.1.0, torchvision 0.3.0, pycuda 2019.1, sacrebleu 1.3.3, SimpleJSON, OpenCV 4.1.1",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 256,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 3133965575612453542,
    "retraining": "N",
    "sample_index_rng_seed": 665484352860916858,
    "samples_per_query": 1,
    "schedule_rng_seed": 3622009729038561421,
    "starting_weights_filename": "frozen_inference_graph.pb",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/TitanRTXx4",
    "system_name": "SCAN 3XS DBP T496X2 Fluid",
    "target_latency (ns)": 10000000,
    "target_qps": 82000,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 48,
    "uid": "5c00248141e186c0",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 21812470,
    "90.00 percentile latency (ns)": 31960737,
    "95.00 percentile latency (ns)": 35370624,
    "97.00 percentile latency (ns)": 37639241,
    "99.00 percentile latency (ns)": 42369296,
    "99.90 percentile latency (ns)": 50621560,
    "Completed samples per second": 1550.44,
    "Max latency (ns)": 57349357,
    "Mean latency (ns)": 22266693,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 11414696,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1550.75,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA TITAN RTX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "characteristics.mAP": 20.067,
    "characteristics.scheduled_queries_per_second": 1550.75,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 387.6875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 387.6875,
    "ck_system": "TitanRTXx4",
    "ck_used": false,
    "cooling": "watercooled",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3, libjemalloc2, cub 1.8.0, tensorrt-laboratory mlperf branch",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 24,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) 8268",
    "host_processors_per_node": 2,
    "host_storage_capacity": "3.84 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-large",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.5",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/results/TitanRTXx4",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.3",
    "other_software_stack": "docker 18.09.2, python 3.6.8,gcc 5.5.0,onnx 1.3.0, tensorflow 1.13.1, pytorch 1.1.0, torchvision 0.3.0, pycuda 2019.1, sacrebleu 1.3.3, SimpleJSON, OpenCV 4.1.1",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 3133965575612453542,
    "retraining": "N",
    "sample_index_rng_seed": 665484352860916858,
    "samples_per_query": 1,
    "schedule_rng_seed": 3622009729038561421,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/TitanRTXx4",
    "system_name": "SCAN 3XS DBP T496X2 Fluid",
    "target_latency (ns)": 100000000,
    "target_qps": 1550,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 48,
    "uid": "92944caf33486f99",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 7816268,
    "90.00 percentile latency (ns)": 8235569,
    "95.00 percentile latency (ns)": 8424480,
    "97.00 percentile latency (ns)": 8622876,
    "99.00 percentile latency (ns)": 9255124,
    "99.90 percentile latency (ns)": 18684312,
    "Completed samples per second": 129042.05,
    "Max latency (ns)": 32934643,
    "Mean latency (ns)": 7846933,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5582962,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 129056.78,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA Tesla T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "characteristics.mAP": 22.912,
    "characteristics.scheduled_queries_per_second": 129056.78,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 6452.839,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 6452.839,
    "ck_system": "T4x20",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3, libjemalloc2, cub 1.8.0, tensorrt-laboratory mlperf branch",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-small",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.5",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/results/T4x20",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.3",
    "other_software_stack": "docker 18.09.2, python 3.6.8,gcc 5.5.0,onnx 1.3.0, tensorflow 1.13.1, pytorch 1.1.0, torchvision 0.3.0, pycuda 2019.1, sacrebleu 1.3.3, SimpleJSON, OpenCV 4.1.1",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 256,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 3133965575612453542,
    "retraining": "N",
    "sample_index_rng_seed": 665484352860916858,
    "samples_per_query": 1,
    "schedule_rng_seed": 3622009729038561421,
    "starting_weights_filename": "frozen_inference_graph.pb",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 20xT4",
    "target_latency (ns)": 10000000,
    "target_qps": 129000,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "2078ff3d0b0afe2f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 34052052,
    "90.00 percentile latency (ns)": 54411138,
    "95.00 percentile latency (ns)": 64597369,
    "97.00 percentile latency (ns)": 69325388,
    "99.00 percentile latency (ns)": 76475046,
    "99.90 percentile latency (ns)": 87979526,
    "Completed samples per second": 2580.04,
    "Max latency (ns)": 102254613,
    "Mean latency (ns)": 38002411,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 21836980,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 2581.24,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA Tesla T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "characteristics.mAP": 20.067,
    "characteristics.scheduled_queries_per_second": 2581.24,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 129.06199999999998,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 129.06199999999998,
    "ck_system": "T4x20",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3, libjemalloc2, cub 1.8.0, tensorrt-laboratory mlperf branch",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-large",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.5",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/results/T4x20",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.3",
    "other_software_stack": "docker 18.09.2, python 3.6.8,gcc 5.5.0,onnx 1.3.0, tensorflow 1.13.1, pytorch 1.1.0, torchvision 0.3.0, pycuda 2019.1, sacrebleu 1.3.3, SimpleJSON, OpenCV 4.1.1",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 3133965575612453542,
    "retraining": "N",
    "sample_index_rng_seed": 665484352860916858,
    "samples_per_query": 1,
    "schedule_rng_seed": 3622009729038561421,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 20xT4",
    "target_latency (ns)": 100000000,
    "target_qps": 2580,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "2f9df345f5bd9bc8",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 6254343,
    "90.00 percentile latency (ns)": 6643742,
    "95.00 percentile latency (ns)": 6805737,
    "97.00 percentile latency (ns)": 6945763,
    "99.00 percentile latency (ns)": 7389314,
    "99.90 percentile latency (ns)": 14786006,
    "Completed samples per second": 56614.98,
    "Max latency (ns)": 27154254,
    "Mean latency (ns)": 6298878,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4468846,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 56620.0,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA Tesla T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "characteristics.mAP": 22.912,
    "characteristics.scheduled_queries_per_second": 56620.0,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 7077.5,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 7077.5,
    "ck_system": "T4x8",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3, libjemalloc2, cub 1.8.0, tensorrt-laboratory mlperf branch",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-small",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.5",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/results/T4x8",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.3",
    "other_software_stack": "docker 18.09.2, python 3.6.8,gcc 5.5.0,onnx 1.3.0, tensorflow 1.13.1, pytorch 1.1.0, torchvision 0.3.0, pycuda 2019.1, sacrebleu 1.3.3, SimpleJSON, OpenCV 4.1.1",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 256,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 3133965575612453542,
    "retraining": "N",
    "sample_index_rng_seed": 665484352860916858,
    "samples_per_query": 1,
    "schedule_rng_seed": 3622009729038561421,
    "starting_weights_filename": "frozen_inference_graph.pb",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 8xT4",
    "target_latency (ns)": 10000000,
    "target_qps": 56600,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "d59d77d66854d9da",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 33927644,
    "90.00 percentile latency (ns)": 48171986,
    "95.00 percentile latency (ns)": 54151965,
    "97.00 percentile latency (ns)": 58163097,
    "99.00 percentile latency (ns)": 66471489,
    "99.90 percentile latency (ns)": 81576764,
    "Completed samples per second": 1010.37,
    "Max latency (ns)": 100438032,
    "Mean latency (ns)": 36702509,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 22695450,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1010.49,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA Tesla T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "characteristics.mAP": 20.067,
    "characteristics.scheduled_queries_per_second": 1010.49,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 126.31125,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 126.31125,
    "ck_system": "T4x8",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 6.0, CUDA 10.1, cuDNN 7.6.3, libjemalloc2, cub 1.8.0, tensorrt-laboratory mlperf branch",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-large",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.5",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.5/tree/master/closed/NVIDIA/results/T4x8",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.3",
    "other_software_stack": "docker 18.09.2, python 3.6.8,gcc 5.5.0,onnx 1.3.0, tensorflow 1.13.1, pytorch 1.1.0, torchvision 0.3.0, pycuda 2019.1, sacrebleu 1.3.3, SimpleJSON, OpenCV 4.1.1",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 3133965575612453542,
    "retraining": "N",
    "sample_index_rng_seed": 665484352860916858,
    "samples_per_query": 1,
    "schedule_rng_seed": 3622009729038561421,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 8xT4",
    "target_latency (ns)": 100000000,
    "target_qps": 1010,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "1a442d387a5ada1c",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 25224099,
    "90.00 percentile latency (ns)": 48653169,
    "95.00 percentile latency (ns)": 54700445,
    "97.00 percentile latency (ns)": 58522388,
    "99.00 percentile latency (ns)": 65546244,
    "99.90 percentile latency (ns)": 77120511,
    "Completed samples per second": 1999.65,
    "Max latency (ns)": 100825672,
    "Mean latency (ns)": 27561335,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4573842,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1999.68,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 1999.68,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 249.96,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 249.96,
    "ck_system": "A10x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 2000,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "78e4d32c4f6caf27",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 37786964,
    "90.00 percentile latency (ns)": 61202056,
    "95.00 percentile latency (ns)": 66251822,
    "97.00 percentile latency (ns)": 71932668,
    "99.00 percentile latency (ns)": 84253142,
    "99.90 percentile latency (ns)": 202457973,
    "Completed samples per second": 5792.32,
    "Max latency (ns)": 1010087315,
    "Mean latency (ns)": 36042919,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 15656566,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_MultiMigServer",
    "Scenario": "server",
    "Scheduled samples per second": 5802.07,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (7x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 5802.07,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 725.25875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 725.25875,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB-MIG-7x1g.10gb, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 5800,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "0e84395bfa5c8597",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 30232782,
    "90.00 percentile latency (ns)": 55172496,
    "95.00 percentile latency (ns)": 63772173,
    "97.00 percentile latency (ns)": 70317945,
    "99.00 percentile latency (ns)": 89333977,
    "99.90 percentile latency (ns)": 113750911,
    "Completed samples per second": 926.42,
    "Max latency (ns)": 147646939,
    "Mean latency (ns)": 33356551,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8948124,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 926.47,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 926.47,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 926.47,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 926.47,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 925,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "e178344ff95688fa",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 54198301,
    "90.00 percentile latency (ns)": 69129717,
    "95.00 percentile latency (ns)": 80847341,
    "97.00 percentile latency (ns)": 86949291,
    "99.00 percentile latency (ns)": 98161441,
    "99.90 percentile latency (ns)": 125310357,
    "Completed samples per second": 15.54,
    "Max latency (ns)": 199103693,
    "Mean latency (ns)": 56772605,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 38633537,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 15.54,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "N/A",
    "accelerator_memory_configuration": "",
    "accelerator_model_name": "N/A",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 0,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 19.858,
    "characteristics.scheduled_queries_per_second": 15.54,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 0.27749999999999997,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 7.77,
    "ck_system": "Triton_CPU_2S_6258Rx1",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "OpenVino 2021.2.200",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "6 slots / 32GB each / 2934 MT/s per socket",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Gold 6258R CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "fp32",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 56,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Triton_CPU_2S_6258Rx1",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5 LTS",
    "other_hardware": "",
    "other_software_stack": "OpenVino 2021.2.200, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "No",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "The original weight filename: https://zenodo.org/record/3228411/files/resnet34-ssd1200.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "CPU Inference on Triton Inference Server",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Triton_CPU_2S_6258Rx1",
    "system_name": "Supermicro X11Dpi-NT Server (Cascade Lake running Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 15.5,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "4ac3fc2ea24208ed",
    "use_accelerator": false,
    "weight_data_types": "int8",
    "weight_transformations": "We transfer the weight from fp32 datatype in ONNX file to int8 datatype in OpenVino IR file."
  },
  {
    "50.00 percentile latency (ns)": 26319906,
    "90.00 percentile latency (ns)": 52122304,
    "95.00 percentile latency (ns)": 59879209,
    "97.00 percentile latency (ns)": 65704261,
    "99.00 percentile latency (ns)": 81861260,
    "99.90 percentile latency (ns)": 107373392,
    "Completed samples per second": 909.86,
    "Max latency (ns)": 1004608757,
    "Mean latency (ns)": 30566223,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8940033,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 911.38,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 911.38,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 911.38,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 911.38,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 910,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "a4b6e943af320608",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 25700562,
    "90.00 percentile latency (ns)": 37572202,
    "95.00 percentile latency (ns)": 40352131,
    "97.00 percentile latency (ns)": 42335035,
    "99.00 percentile latency (ns)": 46812275,
    "99.90 percentile latency (ns)": 55029707,
    "Completed samples per second": 3574.43,
    "Max latency (ns)": 68180914,
    "Mean latency (ns)": 27598831,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 17568322,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 3574.64,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 3574.64,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 446.83,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 446.83,
    "ck_system": "A30x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 3572.8,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "3ad2930c4094cb6c",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 43019917,
    "90.00 percentile latency (ns)": 60096301,
    "95.00 percentile latency (ns)": 65935809,
    "97.00 percentile latency (ns)": 70051012,
    "99.00 percentile latency (ns)": 78857077,
    "99.90 percentile latency (ns)": 95987603,
    "Completed samples per second": 3574.57,
    "Max latency (ns)": 138317319,
    "Mean latency (ns)": 42946469,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 3829112,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 3574.64,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 3574.64,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 446.83,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 446.83,
    "ck_system": "A30x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 3572.8,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "f9c9432687ce7ae5",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 32889588,
    "90.00 percentile latency (ns)": 50470312,
    "95.00 percentile latency (ns)": 57858019,
    "97.00 percentile latency (ns)": 62469680,
    "99.00 percentile latency (ns)": 74329844,
    "99.90 percentile latency (ns)": 88210307,
    "Completed samples per second": 5701.57,
    "Max latency (ns)": 97385363,
    "Mean latency (ns)": 34328429,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 11067431,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 5701.91,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.power": 2259.6413333333335,
    "characteristics.power.normalized_per_core": 282.4551666666667,
    "characteristics.power.normalized_per_processor": 282.4551666666667,
    "characteristics.scheduled_queries_per_second": 5701.91,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 712.73875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 712.73875,
    "ck_system": "A100-PCIex8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex8_TRT_MaxQ",
    "system_name": "Gigabyte G482-Z54 (8x A100-PCIe, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 5700,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "1d491d4626bb50ab",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 32020532,
    "90.00 percentile latency (ns)": 51751084,
    "95.00 percentile latency (ns)": 58996439,
    "97.00 percentile latency (ns)": 62662951,
    "99.00 percentile latency (ns)": 70738326,
    "99.90 percentile latency (ns)": 80159545,
    "Completed samples per second": 7653.93,
    "Max latency (ns)": 87402679,
    "Mean latency (ns)": 32791932,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8912382,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 7654.41,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 7654.41,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 956.80125,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 956.80125,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 7650,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "bb39746d89056ed4",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 15945452,
    "90.00 percentile latency (ns)": 21744163,
    "95.00 percentile latency (ns)": 23583942,
    "97.00 percentile latency (ns)": 25006752,
    "99.00 percentile latency (ns)": 27779946,
    "99.90 percentile latency (ns)": 33719689,
    "Completed samples per second": 3080.79,
    "Max latency (ns)": 43124081,
    "Mean latency (ns)": 16703208,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10991709,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 3080.96,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 3080.96,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 770.24,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 770.24,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 3080,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 64,
    "uid": "004f8fa202bfe1c4",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 31646329,
    "90.00 percentile latency (ns)": 58881554,
    "95.00 percentile latency (ns)": 69914907,
    "97.00 percentile latency (ns)": 77813938,
    "99.00 percentile latency (ns)": 95832076,
    "99.90 percentile latency (ns)": 140982698,
    "Completed samples per second": 100.23,
    "Max latency (ns)": 238454617,
    "Mean latency (ns)": 35861422,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8300779,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 100.23,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 100.23,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 100.23,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 100.23,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 100,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "0132b50d4a7c99dc",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 19708865,
    "90.00 percentile latency (ns)": 27823500,
    "95.00 percentile latency (ns)": 30879033,
    "97.00 percentile latency (ns)": 33156266,
    "99.00 percentile latency (ns)": 38106718,
    "99.90 percentile latency (ns)": 48216222,
    "Completed samples per second": 3080.79,
    "Max latency (ns)": 60061622,
    "Mean latency (ns)": 20383567,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10977800,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 3080.96,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.power": 1266.8609999999985,
    "characteristics.power.normalized_per_core": 316.7152499999996,
    "characteristics.power.normalized_per_processor": 316.7152499999996,
    "characteristics.scheduled_queries_per_second": 3080.96,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 770.24,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 770.24,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 3080,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 64,
    "uid": "f75bc21e44f9440a",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 16942744,
    "90.00 percentile latency (ns)": 24618832,
    "95.00 percentile latency (ns)": 27495582,
    "97.00 percentile latency (ns)": 29135015,
    "99.00 percentile latency (ns)": 32097221,
    "99.90 percentile latency (ns)": 37133912,
    "Completed samples per second": 6161.13,
    "Max latency (ns)": 49037611,
    "Mean latency (ns)": 18029668,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10616853,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 6161.51,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 6161.51,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 770.18875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 770.18875,
    "ck_system": "A100-PCIex8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 6160,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "449472bbbf8f369d",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 41941465,
    "90.00 percentile latency (ns)": 58758204,
    "95.00 percentile latency (ns)": 61486216,
    "97.00 percentile latency (ns)": 62700598,
    "99.00 percentile latency (ns)": 64325403,
    "99.90 percentile latency (ns)": 66646350,
    "Completed samples per second": 7091.68,
    "Max latency (ns)": 1009313285,
    "Mean latency (ns)": 40985305,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10813525,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 7103.61,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 7103.61,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 887.95125,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 887.95125,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 7100,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "145b2b61165393cb",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 12883021,
    "90.00 percentile latency (ns)": 17466044,
    "95.00 percentile latency (ns)": 19100452,
    "97.00 percentile latency (ns)": 20269215,
    "99.00 percentile latency (ns)": 23214604,
    "99.90 percentile latency (ns)": 31878406,
    "Completed samples per second": 6301.0,
    "Max latency (ns)": 39133008,
    "Mean latency (ns)": 13556225,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8935094,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 6301.4,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.power": 3459.5571666666615,
    "characteristics.power.normalized_per_core": 432.4446458333327,
    "characteristics.power.normalized_per_processor": 432.4446458333327,
    "characteristics.scheduled_queries_per_second": 6301.4,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 787.675,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 787.675,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 6300,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "48d2f1c443ebed7f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 28045366,
    "90.00 percentile latency (ns)": 30446302,
    "95.00 percentile latency (ns)": 31191134,
    "97.00 percentile latency (ns)": 31708487,
    "99.00 percentile latency (ns)": 32792933,
    "99.90 percentile latency (ns)": 36025227,
    "Completed samples per second": 1999.52,
    "Max latency (ns)": 57965080,
    "Mean latency (ns)": 28182957,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 23461912,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1999.68,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 1999.68,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 249.96,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 249.96,
    "ck_system": "A10x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 2000,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "3e4b74cbc94f61a9",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 41479186,
    "90.00 percentile latency (ns)": 66173390,
    "95.00 percentile latency (ns)": 76065494,
    "97.00 percentile latency (ns)": 83743853,
    "99.00 percentile latency (ns)": 99717607,
    "99.90 percentile latency (ns)": 130550191,
    "Completed samples per second": 68.66,
    "Max latency (ns)": 1089039995,
    "Mean latency (ns)": 47704217,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 34150858,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 68.66,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "N/A",
    "accelerator_memory_configuration": "",
    "accelerator_model_name": "N/A",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 0,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.mAP": 19.858,
    "characteristics.scheduled_queries_per_second": 68.66,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 0.6130357142857142,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 17.165,
    "ck_system": "Triton_CPU_4S_8380Hx1",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "OpenVino 2021.2.200",
    "host_memory_capacity": "1536 GB",
    "host_memory_configuration": "6 slots / 32GB each / 3200 MT/s per socket",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380H CPU @ 2.90GHz",
    "host_processors_per_node": 4,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "fp32",
    "key.accuracy": "characteristics.mAP",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 112,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Triton_CPU_4S_8380Hx1",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5 LTS",
    "other_hardware": "",
    "other_software_stack": "Tensorflow 2.4.0, OpenVino 2021.2.200, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 64,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "No",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "The original weight filename: https://zenodo.org/record/3228411/files/resnet34-ssd1200.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "CPU Inference on Triton Inference Server",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Triton_CPU_4S_8380Hx1",
    "system_name": "Supermicro SYS-240P-TNRT (Cooper Lake running Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 68.5,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 112,
    "uid": "0aad07b142b80d4d",
    "use_accelerator": false,
    "weight_data_types": "int8",
    "weight_transformations": "We transfer the weight from fp32 datatype in ONNX file to int8 datatype in OpenVino IR file."
  },
  {
    "50.00 percentile latency (ns)": 39022088,
    "90.00 percentile latency (ns)": 57403495,
    "95.00 percentile latency (ns)": 60564159,
    "97.00 percentile latency (ns)": 61881208,
    "99.00 percentile latency (ns)": 63557379,
    "99.90 percentile latency (ns)": 65810051,
    "Completed samples per second": 6977.67,
    "Max latency (ns)": 1002537364,
    "Mean latency (ns)": 38580681,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10908041,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 7094.26,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 7094.26,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 886.7825,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 886.7825,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 7100,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "3ee4c21a416195a2",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 31298415,
    "90.00 percentile latency (ns)": 38239895,
    "95.00 percentile latency (ns)": 44149896,
    "97.00 percentile latency (ns)": 47725714,
    "99.00 percentile latency (ns)": 54129718,
    "99.90 percentile latency (ns)": 68017335,
    "Completed samples per second": 2516.98,
    "Max latency (ns)": 78409089,
    "Mean latency (ns)": 32741111,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 23211527,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 2517.74,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 2517.74,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 125.88699999999999,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 125.88699999999999,
    "ck_system": "T4x20_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 2520,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "d50f2b96433397a8",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 29924556,
    "90.00 percentile latency (ns)": 53057621,
    "95.00 percentile latency (ns)": 61220394,
    "97.00 percentile latency (ns)": 66970301,
    "99.00 percentile latency (ns)": 80091591,
    "99.90 percentile latency (ns)": 96321572,
    "Completed samples per second": 1598.41,
    "Max latency (ns)": 108665447,
    "Mean latency (ns)": 32915807,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10967927,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1598.56,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 1598.56,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 799.28,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 799.28,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 1600,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "4fa1256e7e74f1f9",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 18553311,
    "90.00 percentile latency (ns)": 33419329,
    "95.00 percentile latency (ns)": 36410423,
    "97.00 percentile latency (ns)": 38205636,
    "99.00 percentile latency (ns)": 41129481,
    "99.90 percentile latency (ns)": 44700229,
    "Completed samples per second": 7541.57,
    "Max latency (ns)": 48014979,
    "Mean latency (ns)": 21183886,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8991298,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 7546.07,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 7546.07,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 943.25875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 943.25875,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 7550,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "c5b124d8c9a59a88",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 35536463,
    "90.00 percentile latency (ns)": 56938582,
    "95.00 percentile latency (ns)": 67700793,
    "97.00 percentile latency (ns)": 76402286,
    "99.00 percentile latency (ns)": 90759588,
    "99.90 percentile latency (ns)": 111168273,
    "Completed samples per second": 1028.94,
    "Max latency (ns)": 120249272,
    "Mean latency (ns)": 40168483,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 22916457,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "LWIS_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1029.08,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 1029.08,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 128.635,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 128.635,
    "ck_system": "T4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 1030,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "059d3f54ef0a7c22",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 33272249,
    "90.00 percentile latency (ns)": 51922396,
    "95.00 percentile latency (ns)": 54630452,
    "97.00 percentile latency (ns)": 56452964,
    "99.00 percentile latency (ns)": 59399503,
    "99.90 percentile latency (ns)": 64039095,
    "Completed samples per second": 2397.52,
    "Max latency (ns)": 77750118,
    "Mean latency (ns)": 34326309,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 11410738,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 2397.85,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 2397.85,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 119.8925,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 119.8925,
    "ck_system": "T4x20_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT_Triton",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 2400,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "81157474ec9a8eca",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 35557612,
    "90.00 percentile latency (ns)": 65277753,
    "95.00 percentile latency (ns)": 75769125,
    "97.00 percentile latency (ns)": 81677206,
    "99.00 percentile latency (ns)": 91720083,
    "99.90 percentile latency (ns)": 103873959,
    "Completed samples per second": 749.18,
    "Max latency (ns)": 122946973,
    "Mean latency (ns)": 41089415,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 21705376,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 749.33,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 749.33,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 93.66625,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 93.66625,
    "ck_system": "T4x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 750,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 56,
    "uid": "ca10e71467c465ba",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 42527028,
    "90.00 percentile latency (ns)": 66566819,
    "95.00 percentile latency (ns)": 70535887,
    "97.00 percentile latency (ns)": 72508079,
    "99.00 percentile latency (ns)": 75675472,
    "99.90 percentile latency (ns)": 83356235,
    "Completed samples per second": 1570.87,
    "Max latency (ns)": 91982585,
    "Mean latency (ns)": 42361030,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10933523,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1571.09,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.mAP": 20.111,
    "characteristics.scheduled_queries_per_second": 1571.09,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 785.545,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 785.545,
    "ck_system": "A100-PCIex2_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "COCO 2017 (300x300)",
    "dataset_link": "https://github.com/ctuning/ck/blob/master/docs/mlperf-automation/datasets/coco2017.md",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.mAP",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "ssd-mobilenet",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "https://github.com/octoml/mlops/tree/main/package, https://github.com/ctuning/ai/tree/main/package",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "ssd-resnet34",
    "input_data_types": "int8",
    "key.accuracy": "characteristics.mAP",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 64,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "resnet34-ssd1200.pytorch",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT_Triton",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 100000000,
    "target_qps": 1572.5,
    "task": "object detection",
    "task2": "object detection",
    "total_cores": 128,
    "uid": "ba07574149a48240",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  }
]
