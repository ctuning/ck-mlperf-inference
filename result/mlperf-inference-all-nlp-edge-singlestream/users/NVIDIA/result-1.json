[
  {
    "50.00 percentile latency (ns)": 2342132,
    "90.00 percentile latency (ns)": 2561073,
    "90th percentile latency (ns)": 2561073,
    "95.00 percentile latency (ns)": 2776712,
    "97.00 percentile latency (ns)": 2862862,
    "99.00 percentile latency (ns)": 4568150,
    "99.90 percentile latency (ns)": 4760230,
    "Max latency (ns)": 23197697,
    "Mean latency (ns)": 2435946,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2199473,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 405.65,
    "QPS w/o loadgen overhead": 410.52,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 2.561073,
    "characteristics.90th_percentile_latency_ns": 2561073.0,
    "characteristics.90th_percentile_latency_s": 0.002561073,
    "characteristics.90th_percentile_latency_us": 2561.073,
    "ck_system": "A30x1_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x1_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x1_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (1x A30, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 294.118,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "e18459f80408580f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 43130568,
    "90.00 percentile latency (ns)": 57538713,
    "90th percentile latency (ns)": 57538713,
    "95.00 percentile latency (ns)": 59828858,
    "97.00 percentile latency (ns)": 61363920,
    "99.00 percentile latency (ns)": 61648627,
    "99.90 percentile latency (ns)": 61770524,
    "Max latency (ns)": 65071180,
    "Mean latency (ns)": 43650676,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 17150021,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 22.9,
    "QPS w/o loadgen overhead": 22.91,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 57.538713,
    "characteristics.90th_percentile_latency_ns": 57538713.0,
    "characteristics.90th_percentile_latency_s": 0.057538713,
    "characteristics.90th_percentile_latency_us": 57538.713,
    "characteristics.power": 0.58970071396542,
    "characteristics.power.normalized_per_core": 0.58970071396542,
    "characteristics.power.normalized_per_processor": 0.58970071396542,
    "ck_system": "Xavier_NX_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "8 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 6,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "Micro SD Card",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Xavier_NX_TRT_MaxQ",
    "system_name": "NVIDIA Jetson Xavier NX (MaxQ, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 20,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 6,
    "uid": "520b4ab98ee531be",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1700211,
    "90.00 percentile latency (ns)": 1779320,
    "90th percentile latency (ns)": 1779320,
    "95.00 percentile latency (ns)": 1843966,
    "97.00 percentile latency (ns)": 1918806,
    "99.00 percentile latency (ns)": 3649165,
    "99.90 percentile latency (ns)": 4184002,
    "Max latency (ns)": 12371107,
    "Mean latency (ns)": 1762910,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1588270,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 558.62,
    "QPS w/o loadgen overhead": 567.24,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 1.77932,
    "characteristics.90th_percentile_latency_ns": 1779320.0,
    "characteristics.90th_percentile_latency_s": 0.00177932,
    "characteristics.90th_percentile_latency_us": 1779.32,
    "ck_system": "A100-PCIex1_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex1_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex1_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (1x A100-PCIe, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "d14ec79ef5b23bfc",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 20609609,
    "90.00 percentile latency (ns)": 31091144,
    "90th percentile latency (ns)": 31091144,
    "95.00 percentile latency (ns)": 32101435,
    "97.00 percentile latency (ns)": 32498352,
    "99.00 percentile latency (ns)": 32832193,
    "99.90 percentile latency (ns)": 33199091,
    "Max latency (ns)": 33466114,
    "Mean latency (ns)": 21813724,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 9722519,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 45.78,
    "QPS w/o loadgen overhead": 45.84,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA AGX Xavier",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 31.091144,
    "characteristics.90th_percentile_latency_ns": 31091144.0,
    "characteristics.90th_percentile_latency_s": 0.031091144,
    "characteristics.90th_percentile_latency_us": 31091.144,
    "ck_system": "AGX_Xavier_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "32 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 8,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "eMMC 5.1",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/AGX_Xavier_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/AGX_Xavier_TRT",
    "system_name": "NVIDIA Jetson AGX Xavier 32GB (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 32.2581,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 8,
    "uid": "8852ed82c854a0a9",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1565562,
    "90.00 percentile latency (ns)": 1708807,
    "90th percentile latency (ns)": 1708807,
    "95.00 percentile latency (ns)": 1768102,
    "97.00 percentile latency (ns)": 1823835,
    "99.00 percentile latency (ns)": 1832915,
    "99.90 percentile latency (ns)": 1840946,
    "Max latency (ns)": 16022567,
    "Mean latency (ns)": 1593010,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1472255,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 622.45,
    "QPS w/o loadgen overhead": 627.74,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 1.708807,
    "characteristics.90th_percentile_latency_ns": 1708807.0,
    "characteristics.90th_percentile_latency_s": 0.001708807,
    "characteristics.90th_percentile_latency_us": 1708.807,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_edge",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_edge",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_edge",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "f7fd4b04b3795895",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 5518167,
    "90.00 percentile latency (ns)": 6460815,
    "90th percentile latency (ns)": 6460815,
    "95.00 percentile latency (ns)": 6867808,
    "97.00 percentile latency (ns)": 10179218,
    "99.00 percentile latency (ns)": 10221878,
    "99.90 percentile latency (ns)": 10286238,
    "Max latency (ns)": 14062900,
    "Mean latency (ns)": 5686014,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4592081,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 175.7,
    "QPS w/o loadgen overhead": 175.87,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 6.460815,
    "characteristics.90th_percentile_latency_ns": 6460815.0,
    "characteristics.90th_percentile_latency_s": 0.006460815,
    "characteristics.90th_percentile_latency_us": 6460.815,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "0e03c7464184f3ea",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 34734823,
    "90.00 percentile latency (ns)": 53540217,
    "90th percentile latency (ns)": 53540217,
    "95.00 percentile latency (ns)": 56157917,
    "97.00 percentile latency (ns)": 57284068,
    "99.00 percentile latency (ns)": 57527970,
    "99.90 percentile latency (ns)": 57721066,
    "Max latency (ns)": 58017480,
    "Mean latency (ns)": 36570694,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 15348224,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 27.33,
    "QPS w/o loadgen overhead": 27.34,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA AGX Xavier",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 53.540217,
    "characteristics.90th_percentile_latency_ns": 53540217.0,
    "characteristics.90th_percentile_latency_s": 0.053540217,
    "characteristics.90th_percentile_latency_us": 53540.217,
    "characteristics.power": 0.6719735394359012,
    "characteristics.power.normalized_per_core": 0.6719735394359012,
    "characteristics.power.normalized_per_processor": 0.6719735394359012,
    "ck_system": "AGX_Xavier_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "32 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 8,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "eMMC 5.1",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/AGX_Xavier_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/AGX_Xavier_TRT_MaxQ",
    "system_name": "NVIDIA Jetson AGX Xavier 32GB (MaxQ, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 32.2581,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 8,
    "uid": "10456ab651241c9b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 5923459,
    "90.00 percentile latency (ns)": 7542141,
    "90th percentile latency (ns)": 7542141,
    "95.00 percentile latency (ns)": 7779103,
    "97.00 percentile latency (ns)": 8009820,
    "99.00 percentile latency (ns)": 8088236,
    "99.90 percentile latency (ns)": 8107924,
    "Max latency (ns)": 11332632,
    "Mean latency (ns)": 6041106,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4762893,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 164.48,
    "QPS w/o loadgen overhead": 165.53,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30 (1x1g.3gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 7.542141,
    "characteristics.90th_percentile_latency_ns": 7542141.0,
    "characteristics.90th_percentile_latency_s": 0.007542141,
    "characteristics.90th_percentile_latency_us": 7542.141,
    "ck_system": "A30-MIG_1x1g.3gb_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.3gb_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30-MIG_1x1g.3gb_TRT",
    "system_name": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.3gb, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 134.177,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "5eea2784922bae63",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 2785527,
    "90.00 percentile latency (ns)": 2897452,
    "90th percentile latency (ns)": 2897452,
    "95.00 percentile latency (ns)": 2949598,
    "97.00 percentile latency (ns)": 3015670,
    "99.00 percentile latency (ns)": 5014987,
    "99.90 percentile latency (ns)": 5357748,
    "Max latency (ns)": 15118054,
    "Mean latency (ns)": 2845582,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2537790,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 342.0,
    "QPS w/o loadgen overhead": 351.42,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 2.897452,
    "characteristics.90th_percentile_latency_ns": 2897452.0,
    "characteristics.90th_percentile_latency_s": 0.002897452,
    "characteristics.90th_percentile_latency_us": 2897.452,
    "ck_system": "A10x1_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x1_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x1_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (1x A10, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 357.143,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "41941d3819c11122",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1644754,
    "90.00 percentile latency (ns)": 1725456,
    "90th percentile latency (ns)": 1725456,
    "95.00 percentile latency (ns)": 1786831,
    "97.00 percentile latency (ns)": 1837796,
    "99.00 percentile latency (ns)": 2878067,
    "99.90 percentile latency (ns)": 3040051,
    "Max latency (ns)": 7705278,
    "Mean latency (ns)": 1685459,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1577689,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 591.09,
    "QPS w/o loadgen overhead": 593.31,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 1.725456,
    "characteristics.90th_percentile_latency_ns": 1725456.0,
    "characteristics.90th_percentile_latency_s": 0.001725456,
    "characteristics.90th_percentile_latency_us": 1725.456,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_Triton_edge",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_Triton_edge",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_Triton_edge",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "fae972296456b826",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 2613784,
    "90.00 percentile latency (ns)": 2839189,
    "90th percentile latency (ns)": 2839189,
    "95.00 percentile latency (ns)": 2898156,
    "97.00 percentile latency (ns)": 2926023,
    "99.00 percentile latency (ns)": 2972269,
    "99.90 percentile latency (ns)": 3078020,
    "Max latency (ns)": 10959812,
    "Mean latency (ns)": 2641242,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2369217,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 369.67,
    "QPS w/o loadgen overhead": 378.61,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 2.839189,
    "characteristics.90th_percentile_latency_ns": 2839189.0,
    "characteristics.90th_percentile_latency_s": 0.002839189,
    "characteristics.90th_percentile_latency_us": 2839.189,
    "ck_system": "A10x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x1_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x1_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (1x A10, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 357.143,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "9bb6b42968133ea2",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 2137813,
    "90.00 percentile latency (ns)": 2536262,
    "90th percentile latency (ns)": 2536262,
    "95.00 percentile latency (ns)": 2667831,
    "97.00 percentile latency (ns)": 2805650,
    "99.00 percentile latency (ns)": 2846000,
    "99.90 percentile latency (ns)": 2866361,
    "Max latency (ns)": 9113280,
    "Mean latency (ns)": 2211811,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1987873,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 446.47,
    "QPS w/o loadgen overhead": 452.12,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 2.536262,
    "characteristics.90th_percentile_latency_ns": 2536262.0,
    "characteristics.90th_percentile_latency_s": 0.002536262,
    "characteristics.90th_percentile_latency_us": 2536.262,
    "ck_system": "A30x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x1_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x1_TRT",
    "system_name": "Gigabyte G482-Z54 (1x A30, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "153b8642f8806428",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 12596033,
    "90.00 percentile latency (ns)": 14210247,
    "90th percentile latency (ns)": 14210247,
    "95.00 percentile latency (ns)": 14471723,
    "97.00 percentile latency (ns)": 14702248,
    "99.00 percentile latency (ns)": 14836327,
    "99.90 percentile latency (ns)": 14874617,
    "Max latency (ns)": 25200337,
    "Mean latency (ns)": 12682713,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5173755,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 78.62,
    "QPS w/o loadgen overhead": 78.85,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30 (1x1g.3gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 14.210247,
    "characteristics.90th_percentile_latency_ns": 14210247.0,
    "characteristics.90th_percentile_latency_s": 0.014210247,
    "characteristics.90th_percentile_latency_us": 14210.247,
    "ck_system": "A30-MIG_1x1g.3gb_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30-MIG_1x1g.3gb_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30-MIG_1x1g.3gb_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (1x A30-MIG-1x1g.3gb, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 70.2801,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "5e312a4844ffb701",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 4641744,
    "90.00 percentile latency (ns)": 6371598,
    "90th percentile latency (ns)": 6371598,
    "95.00 percentile latency (ns)": 6467618,
    "97.00 percentile latency (ns)": 6578386,
    "99.00 percentile latency (ns)": 6618431,
    "99.90 percentile latency (ns)": 6628529,
    "Max latency (ns)": 8655130,
    "Mean latency (ns)": 4777292,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 3705278,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 208.99,
    "QPS w/o loadgen overhead": 209.32,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 6.371598,
    "characteristics.90th_percentile_latency_ns": 6371598.0,
    "characteristics.90th_percentile_latency_s": 0.006371598,
    "characteristics.90th_percentile_latency_us": 6371.598,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "afc4d9c970bef60d",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1587588,
    "90.00 percentile latency (ns)": 1728887,
    "90th percentile latency (ns)": 1728887,
    "95.00 percentile latency (ns)": 1789653,
    "97.00 percentile latency (ns)": 1835843,
    "99.00 percentile latency (ns)": 1848947,
    "99.90 percentile latency (ns)": 2708762,
    "Max latency (ns)": 8936093,
    "Mean latency (ns)": 1617308,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1479985,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 606.84,
    "QPS w/o loadgen overhead": 618.31,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 1.728887,
    "characteristics.90th_percentile_latency_ns": 1728887.0,
    "characteristics.90th_percentile_latency_s": 0.001728887,
    "characteristics.90th_percentile_latency_us": 1728.887,
    "ck_system": "A100-PCIex1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex1_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex1_TRT",
    "system_name": "Gigabyte G482-Z54 (1x A100-PCIe, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "174bcb95605ad651",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 37371589,
    "90.00 percentile latency (ns)": 48929147,
    "90th percentile latency (ns)": 48929147,
    "95.00 percentile latency (ns)": 51050583,
    "97.00 percentile latency (ns)": 52782367,
    "99.00 percentile latency (ns)": 53079807,
    "99.90 percentile latency (ns)": 53179914,
    "Max latency (ns)": 54517860,
    "Mean latency (ns)": 38018507,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 14578089,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "QPS w/ loadgen overhead": 26.29,
    "QPS w/o loadgen overhead": 26.3,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.90th_percentile_latency_ms": 48.929147,
    "characteristics.90th_percentile_latency_ns": 48929147.0,
    "characteristics.90th_percentile_latency_s": 0.048929147,
    "characteristics.90th_percentile_latency_us": 48929.147,
    "ck_system": "Xavier_NX_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2",
    "host_memory_capacity": "8 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 6,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32 GB",
    "host_storage_type": "Micro SD Card",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1024,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Xavier_NX_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "21.03 Jetson CUDA-X AI Developer Preview, TensorRT 7.2.3, CUDA 10.2, cuDNN 8.0.0, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Xavier_NX_TRT",
    "system_name": "NVIDIA Jetson Xavier NX (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 20,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 6,
    "uid": "e21f81554e242d19",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1593159,
    "90.00 percentile latency (ns)": 1741417,
    "90th percentile latency (ns)": 1741417,
    "95.00 percentile latency (ns)": 1817289,
    "97.00 percentile latency (ns)": 1856713,
    "99.00 percentile latency (ns)": 1868495,
    "99.90 percentile latency (ns)": 1924961,
    "Max latency (ns)": 5953889,
    "Mean latency (ns)": 1622671,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1500284,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 613.73,
    "QPS w/o loadgen overhead": 616.27,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 1.741417,
    "characteristics.90th_percentile_latency_ns": 1741417.0,
    "characteristics.90th_percentile_latency_s": 0.001741417,
    "characteristics.90th_percentile_latency_us": 1741.417,
    "ck_system": "DGX-A100_A100-SXM4x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x1_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x1_TRT",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM4, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "40d8ac626eacd9a4",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 9192581,
    "90.00 percentile latency (ns)": 10992868,
    "90th percentile latency (ns)": 10992868,
    "95.00 percentile latency (ns)": 11096462,
    "97.00 percentile latency (ns)": 11242276,
    "99.00 percentile latency (ns)": 11325992,
    "99.90 percentile latency (ns)": 11406353,
    "Max latency (ns)": 11503325,
    "Mean latency (ns)": 9055954,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4591783,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 110.37,
    "QPS w/o loadgen overhead": 110.42,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "5GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4 (1x1g.5gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 10.992868,
    "characteristics.90th_percentile_latency_ns": 10992868.0,
    "characteristics.90th_percentile_latency_s": 0.010992868,
    "characteristics.90th_percentile_latency_us": 10992.868,
    "ck_system": "DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM4-MIG-1x1g.5gb, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "42e09219c7534996",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1861709,
    "90.00 percentile latency (ns)": 1949327,
    "90th percentile latency (ns)": 1949327,
    "95.00 percentile latency (ns)": 2017215,
    "97.00 percentile latency (ns)": 2107844,
    "99.00 percentile latency (ns)": 3926934,
    "99.90 percentile latency (ns)": 4183909,
    "Max latency (ns)": 9800513,
    "Mean latency (ns)": 1924593,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1759140,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 510.9,
    "QPS w/o loadgen overhead": 519.59,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 1.949327,
    "characteristics.90th_percentile_latency_ns": 1949327.0,
    "characteristics.90th_percentile_latency_s": 0.001949327,
    "characteristics.90th_percentile_latency_us": 1949.327,
    "ck_system": "A100-PCIex1_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex1_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex1_TRT_Triton",
    "system_name": "Gigabyte G482-Z52 (1x A100-PCIe, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "f42ea9783d7caa66",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 20407911,
    "90.00 percentile latency (ns)": 30806756,
    "90th percentile latency (ns)": 30806756,
    "95.00 percentile latency (ns)": 31752718,
    "97.00 percentile latency (ns)": 32290439,
    "99.00 percentile latency (ns)": 32681369,
    "99.90 percentile latency (ns)": 33080779,
    "Max latency (ns)": 33384184,
    "Mean latency (ns)": 21444718,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 9894693,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 46.58,
    "QPS w/o loadgen overhead": 46.63,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA AGX Xavier",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 30.806756,
    "characteristics.90th_percentile_latency_ns": 30806756.0,
    "characteristics.90th_percentile_latency_s": 0.030806756,
    "characteristics.90th_percentile_latency_us": 30806.756,
    "ck_system": "AGX_Xavier_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2",
    "host_memory_capacity": "32GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 8,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32GB",
    "host_storage_type": "eMMC 5.1",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/AGX_Xavier_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/AGX_Xavier_TRT",
    "system_name": "NVIDIA Jetson AGX Xavier 32GB (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 32.2581,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 8,
    "uid": "10d711bbf49868b8",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1770962,
    "90.00 percentile latency (ns)": 1860460,
    "90th percentile latency (ns)": 1860460,
    "95.00 percentile latency (ns)": 1924630,
    "97.00 percentile latency (ns)": 1991766,
    "99.00 percentile latency (ns)": 3032179,
    "99.90 percentile latency (ns)": 3411420,
    "Max latency (ns)": 7820541,
    "Mean latency (ns)": 1816198,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1692665,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 548.5,
    "QPS w/o loadgen overhead": 550.6,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 1.86046,
    "characteristics.90th_percentile_latency_ns": 1860460.0,
    "characteristics.90th_percentile_latency_s": 0.00186046,
    "characteristics.90th_percentile_latency_us": 1860.46,
    "ck_system": "DGX-A100_A100-SXM4x1_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x1_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x1_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM4, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "44440a02e6d5dff1",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 4950825,
    "90.00 percentile latency (ns)": 6759718,
    "90th percentile latency (ns)": 6759718,
    "95.00 percentile latency (ns)": 6881997,
    "97.00 percentile latency (ns)": 7026058,
    "99.00 percentile latency (ns)": 7055242,
    "99.90 percentile latency (ns)": 7096350,
    "Max latency (ns)": 7931275,
    "Mean latency (ns)": 5128691,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4169790,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 194.68,
    "QPS w/o loadgen overhead": 194.98,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "5GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4 (1x1g.5gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 6.759718,
    "characteristics.90th_percentile_latency_ns": 6759718.0,
    "characteristics.90th_percentile_latency_s": 0.006759718,
    "characteristics.90th_percentile_latency_us": 6759.718,
    "ck_system": "DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x1-MIG_1x1g.5gb_TRT",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM4-MIG-1x1g.5gb, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "43c3961fbf6ca2ef",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 6165245,
    "90.00 percentile latency (ns)": 6782306,
    "90th percentile latency (ns)": 6782306,
    "95.00 percentile latency (ns)": 7074628,
    "97.00 percentile latency (ns)": 7363205,
    "99.00 percentile latency (ns)": 9390405,
    "99.90 percentile latency (ns)": 9769979,
    "Max latency (ns)": 14268514,
    "Mean latency (ns)": 6273890,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5380086,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 157.52,
    "QPS w/o loadgen overhead": 159.39,
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 6.782306,
    "characteristics.90th_percentile_latency_ns": 6782306.0,
    "characteristics.90th_percentile_latency_s": 0.006782306,
    "characteristics.90th_percentile_latency_us": 6782.306,
    "ck_system": "T4x1_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x1_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x1_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (1x T4, TensorRT, Triton)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 156.25,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "fbddf40d7b59d8a7",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 5282955,
    "90.00 percentile latency (ns)": 6459832,
    "90th percentile latency (ns)": 6459832,
    "95.00 percentile latency (ns)": 6699812,
    "97.00 percentile latency (ns)": 6799294,
    "99.00 percentile latency (ns)": 6952726,
    "99.90 percentile latency (ns)": 7297947,
    "Max latency (ns)": 10833442,
    "Mean latency (ns)": 5373520,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4242379,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 183.53,
    "QPS w/o loadgen overhead": 186.1,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 6.459832,
    "characteristics.90th_percentile_latency_ns": 6459832.0,
    "characteristics.90th_percentile_latency_s": 0.006459832,
    "characteristics.90th_percentile_latency_us": 6459.832,
    "ck_system": "T4x1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x1_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x1_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (1x T4, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 156.25,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "63b2436f980ef213",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1613042,
    "90.00 percentile latency (ns)": 1759950,
    "90th percentile latency (ns)": 1759950,
    "95.00 percentile latency (ns)": 1836768,
    "97.00 percentile latency (ns)": 1880788,
    "99.00 percentile latency (ns)": 1899938,
    "99.90 percentile latency (ns)": 1974436,
    "Max latency (ns)": 5714402,
    "Mean latency (ns)": 1643462,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1513994,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 599.12,
    "QPS w/o loadgen overhead": 608.47,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 1.75995,
    "characteristics.90th_percentile_latency_ns": 1759950.0,
    "characteristics.90th_percentile_latency_s": 0.00175995,
    "characteristics.90th_percentile_latency_us": 1759.95,
    "ck_system": "A100-PCIex1_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex1_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex1_TRT",
    "system_name": "Gigabyte G482-Z52 (1x A100-PCIe, TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 588.235,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "126c6000b429599f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 37473625,
    "90.00 percentile latency (ns)": 48881385,
    "90th percentile latency (ns)": 48881385,
    "95.00 percentile latency (ns)": 50197687,
    "97.00 percentile latency (ns)": 51641164,
    "99.00 percentile latency (ns)": 52900412,
    "99.90 percentile latency (ns)": 53128028,
    "Max latency (ns)": 53411101,
    "Mean latency (ns)": 37718340,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 14970908,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "QPS w/ loadgen overhead": 26.5,
    "QPS w/o loadgen overhead": 26.51,
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "singlestream",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "Shared with host",
    "accelerator_memory_configuration": "SRAM",
    "accelerator_model_name": "NVIDIA Xavier NX",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.90th_percentile_latency_ms": 48.881385,
    "characteristics.90th_percentile_latency_ns": 48881385.0,
    "characteristics.90th_percentile_latency_s": 0.048881385,
    "characteristics.90th_percentile_latency_us": 48881.385,
    "ck_system": "Xavier_NX_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.90th_percentile_latency_ms",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2",
    "host_memory_capacity": "8GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 6,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "NVIDIA Carmel (ARMv8.2)",
    "host_processors_per_node": 1,
    "host_storage_capacity": "32GB",
    "host_storage_type": "Micro SD Card",
    "hw_notes": "GPU and both DLAs are used in resnet50, ssd-mobilenet, and ssd-resnet34, in Offline and MultiStream scenarios",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1024,
    "mlperf_version": "v0.7",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/Xavier_NX_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "20.09 Jetson CUDA-X AI Developer Preview, TensorRT 7.2, CUDA 10.2, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Xavier_NX_TRT",
    "system_name": "NVIDIA Jetson Xavier NX (TensorRT)",
    "system_type": "edge",
    "target_latency (ns)": 0,
    "target_qps": 20,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 6,
    "uid": "1f82d637424191d1",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  }
]
