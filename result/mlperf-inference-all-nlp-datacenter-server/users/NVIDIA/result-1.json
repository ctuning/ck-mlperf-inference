[
  {
    "50.00 percentile latency (ns)": 40969807,
    "90.00 percentile latency (ns)": 77073635,
    "95.00 percentile latency (ns)": 86973333,
    "97.00 percentile latency (ns)": 94265153,
    "99.00 percentile latency (ns)": 116967189,
    "99.90 percentile latency (ns)": 128459020,
    "Completed samples per second": 7001.79,
    "Max latency (ns)": 136823451,
    "Mean latency (ns)": 45645281,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 11635535,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 7003.11,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 7003.11,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 875.38875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 875.38875,
    "ck_system": "A10x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 7000,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "173bcd3fe3cc3b20",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 21323557,
    "90.00 percentile latency (ns)": 27566486,
    "95.00 percentile latency (ns)": 30251218,
    "97.00 percentile latency (ns)": 32182761,
    "99.00 percentile latency (ns)": 36401507,
    "99.90 percentile latency (ns)": 45208188,
    "Completed samples per second": 3196.46,
    "Max latency (ns)": 1011571934,
    "Mean latency (ns)": 22078708,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10923445,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 3201.83,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 3201.83,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 400.22875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 400.22875,
    "ck_system": "A10x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 3200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "4aceb1626a4b82c8",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 59950491,
    "90.00 percentile latency (ns)": 96909506,
    "95.00 percentile latency (ns)": 101516031,
    "97.00 percentile latency (ns)": 108064254,
    "99.00 percentile latency (ns)": 119391355,
    "99.90 percentile latency (ns)": 154736654,
    "Completed samples per second": 20457.28,
    "Max latency (ns)": 1028543403,
    "Mean latency (ns)": 65253006,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 17379384,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_MultiMigServer",
    "Scenario": "server",
    "Scheduled samples per second": 20491.59,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (7x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 20491.59,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2561.44875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2561.44875,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB-MIG-7x1g.10gb, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 20500,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "d26f5e0a1fa4bb2a",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 75653292,
    "90.00 percentile latency (ns)": 113925221,
    "95.00 percentile latency (ns)": 118423591,
    "97.00 percentile latency (ns)": 121915729,
    "99.00 percentile latency (ns)": 129373528,
    "99.90 percentile latency (ns)": 151248618,
    "Completed samples per second": 9303.29,
    "Max latency (ns)": 1039359087,
    "Mean latency (ns)": 76219954,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 21270035,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_MultiMigServer",
    "Scenario": "server",
    "Scheduled samples per second": 9304.02,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (7x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 9304.02,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1163.0025,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1163.0025,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_56x1g.10gb_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB-MIG-7x1g.10gb, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 9300,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "47a08468789f02f6",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 62476028,
    "90.00 percentile latency (ns)": 82691100,
    "95.00 percentile latency (ns)": 90074400,
    "97.00 percentile latency (ns)": 95808801,
    "99.00 percentile latency (ns)": 120135445,
    "99.90 percentile latency (ns)": 544160214339,
    "Completed samples per second": 3201.46,
    "Max latency (ns)": 605928544101,
    "Mean latency (ns)": 3012272851,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4756359,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 3201.83,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 3201.83,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 3201.83,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 3201.83,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 3200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "aba9d2940efbe95f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 38902247,
    "90.00 percentile latency (ns)": 53493169,
    "95.00 percentile latency (ns)": 58545594,
    "97.00 percentile latency (ns)": 62409861,
    "99.00 percentile latency (ns)": 81138185,
    "99.90 percentile latency (ns)": 538568022544,
    "Completed samples per second": 1552.35,
    "Max latency (ns)": 604926074593,
    "Mean latency (ns)": 2936096302,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4472477,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 1552.5,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 1552.5,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1552.5,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1552.5,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 1550,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "9d4186aa3a1913cc",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 27959067,
    "90.00 percentile latency (ns)": 36330547,
    "95.00 percentile latency (ns)": 39359755,
    "97.00 percentile latency (ns)": 41748913,
    "99.00 percentile latency (ns)": 46981694,
    "99.90 percentile latency (ns)": 57675581,
    "Completed samples per second": 2796.88,
    "Max latency (ns)": 1009868196,
    "Mean latency (ns)": 28209863,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 13080946,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 2801.56,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 2801.56,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2801.56,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2801.56,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 2800,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "c6eba333ac9619c7",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 29032661,
    "90.00 percentile latency (ns)": 40717310,
    "95.00 percentile latency (ns)": 45882631,
    "97.00 percentile latency (ns)": 49651406,
    "99.00 percentile latency (ns)": 57947082,
    "99.90 percentile latency (ns)": 75910767,
    "Completed samples per second": 1400.67,
    "Max latency (ns)": 1006278550,
    "Mean latency (ns)": 29922975,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 11825470,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1403.01,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 1403.01,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1403.01,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1403.01,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 1400,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "4387b52bc4b8826a",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 47162841,
    "90.00 percentile latency (ns)": 70362710,
    "95.00 percentile latency (ns)": 78009610,
    "97.00 percentile latency (ns)": 83408647,
    "99.00 percentile latency (ns)": 97836806,
    "99.90 percentile latency (ns)": 508010705245,
    "Completed samples per second": 11498.76,
    "Max latency (ns)": 603785539504,
    "Mean latency (ns)": 2134366448,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4890960,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 11499.7,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 11499.7,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1437.4625,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1437.4625,
    "ck_system": "A30x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 11500,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "8c38e4ec798791a0",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 51959994,
    "90.00 percentile latency (ns)": 82903223,
    "95.00 percentile latency (ns)": 92865642,
    "97.00 percentile latency (ns)": 100346789,
    "99.00 percentile latency (ns)": 119970511,
    "99.90 percentile latency (ns)": 512175227061,
    "Completed samples per second": 5250.69,
    "Max latency (ns)": 603602375008,
    "Mean latency (ns)": 2045144864,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4364349,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 5251.6,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 5251.6,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 656.45,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 656.45,
    "ck_system": "A30x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 5250,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "75df3ab69a44fa8a",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 28639096,
    "90.00 percentile latency (ns)": 46292136,
    "95.00 percentile latency (ns)": 48095423,
    "97.00 percentile latency (ns)": 49134445,
    "99.00 percentile latency (ns)": 51011351,
    "99.90 percentile latency (ns)": 54560019,
    "Completed samples per second": 11000.3,
    "Max latency (ns)": 80697752,
    "Mean latency (ns)": 29099776,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5174979,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 11000.75,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 11000.75,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1375.09375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1375.09375,
    "ck_system": "A30x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 11000,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "1c7db12219142b4b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 94322826,
    "90.00 percentile latency (ns)": 101580333,
    "95.00 percentile latency (ns)": 103650670,
    "97.00 percentile latency (ns)": 105054102,
    "99.00 percentile latency (ns)": 107939147,
    "99.90 percentile latency (ns)": 112938351,
    "Completed samples per second": 5192.33,
    "Max latency (ns)": 1064885693,
    "Mean latency (ns)": 94389113,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 73769649,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 5201.46,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 5201.46,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 650.1825,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 650.1825,
    "ck_system": "A30x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 5200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "75697c590df28cf7",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 49071218,
    "90.00 percentile latency (ns)": 70274920,
    "95.00 percentile latency (ns)": 76584678,
    "97.00 percentile latency (ns)": 80818011,
    "99.00 percentile latency (ns)": 88815349,
    "99.90 percentile latency (ns)": 101613979,
    "Completed samples per second": 17497.69,
    "Max latency (ns)": 147161725,
    "Mean latency (ns)": 50124965,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5436083,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 17498.52,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 2308.8578333333344,
    "characteristics.power.normalized_per_core": 288.6072291666668,
    "characteristics.power.normalized_per_processor": 288.6072291666668,
    "characteristics.scheduled_queries_per_second": 17498.52,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2187.315,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2187.315,
    "ck_system": "A100-PCIex8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex8_TRT_MaxQ",
    "system_name": "Gigabyte G482-Z54 (8x A100-PCIe, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 17500,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "84bd68e735c248e8",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 36684639,
    "90.00 percentile latency (ns)": 59016736,
    "95.00 percentile latency (ns)": 67159022,
    "97.00 percentile latency (ns)": 72719585,
    "99.00 percentile latency (ns)": 84412378,
    "99.90 percentile latency (ns)": 105878874,
    "Completed samples per second": 7503.57,
    "Max latency (ns)": 141656042,
    "Mean latency (ns)": 39296151,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4201629,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 7504.02,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 2263.458901830283,
    "characteristics.power.normalized_per_core": 282.9323627287854,
    "characteristics.power.normalized_per_processor": 282.9323627287854,
    "characteristics.scheduled_queries_per_second": 7504.02,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 938.0025,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 938.0025,
    "ck_system": "A100-PCIex8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex8_TRT_MaxQ",
    "system_name": "Gigabyte G482-Z54 (8x A100-PCIe, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 7500,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "d47677143a5bc623",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 56815233,
    "90.00 percentile latency (ns)": 63877083,
    "95.00 percentile latency (ns)": 65746934,
    "97.00 percentile latency (ns)": 67203884,
    "99.00 percentile latency (ns)": 98880555,
    "99.90 percentile latency (ns)": 544618554989,
    "Completed samples per second": 25789.64,
    "Max latency (ns)": 606584489643,
    "Mean latency (ns)": 3065111679,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5291881,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 25791.81,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 25791.81,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 3223.97625,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 3223.97625,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 25800,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "e04aa090db6773b9",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 58799924,
    "90.00 percentile latency (ns)": 66627431,
    "95.00 percentile latency (ns)": 69258337,
    "97.00 percentile latency (ns)": 71584396,
    "99.00 percentile latency (ns)": 88504836,
    "99.90 percentile latency (ns)": 545703792377,
    "Completed samples per second": 13098.28,
    "Max latency (ns)": 606892799140,
    "Mean latency (ns)": 3077424365,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5042354,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 13099.47,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 13099.47,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1637.43375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1637.43375,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 13100,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "03a910ddd15643a4",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 44895004,
    "90.00 percentile latency (ns)": 62409169,
    "95.00 percentile latency (ns)": 67345357,
    "97.00 percentile latency (ns)": 70572144,
    "99.00 percentile latency (ns)": 76577763,
    "99.90 percentile latency (ns)": 86691282,
    "Completed samples per second": 10201.93,
    "Max latency (ns)": 109233712,
    "Mean latency (ns)": 45455629,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 7171478,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 10202.91,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 10202.91,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2550.7275,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2550.7275,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 10200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 64,
    "uid": "53d59bb1819a40cc",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 45116187,
    "90.00 percentile latency (ns)": 74091884,
    "95.00 percentile latency (ns)": 84048782,
    "97.00 percentile latency (ns)": 90828047,
    "99.00 percentile latency (ns)": 104473902,
    "99.90 percentile latency (ns)": 127917024,
    "Completed samples per second": 4860.09,
    "Max latency (ns)": 160326613,
    "Mean latency (ns)": 48178310,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4567331,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 4860.48,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 4860.48,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1215.12,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1215.12,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 4860,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 64,
    "uid": "4b15cbfebc2405db",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 43399605,
    "90.00 percentile latency (ns)": 65405764,
    "95.00 percentile latency (ns)": 72425955,
    "97.00 percentile latency (ns)": 77633912,
    "99.00 percentile latency (ns)": 104502627,
    "99.90 percentile latency (ns)": 639468565526,
    "Completed samples per second": 380.85,
    "Max latency (ns)": 713430495840,
    "Mean latency (ns)": 3414767754,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4144423,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 380.87,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 380.87,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 380.87,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 380.87,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 380,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "b8118a149024a828",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 41756784,
    "90.00 percentile latency (ns)": 68837397,
    "95.00 percentile latency (ns)": 77358698,
    "97.00 percentile latency (ns)": 83544848,
    "99.00 percentile latency (ns)": 124818067,
    "99.90 percentile latency (ns)": 1523088211364,
    "Completed samples per second": 160.36,
    "Max latency (ns)": 1693043705445,
    "Mean latency (ns)": 8237650556,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 6751918,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 160.37,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 160.37,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 160.37,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 160.37,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 160,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "4cb5b4b45f593022",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 76377888,
    "90.00 percentile latency (ns)": 100676496,
    "95.00 percentile latency (ns)": 106157432,
    "97.00 percentile latency (ns)": 109260585,
    "99.00 percentile latency (ns)": 114593008,
    "99.90 percentile latency (ns)": 122845331,
    "Completed samples per second": 10201.3,
    "Max latency (ns)": 136300178,
    "Mean latency (ns)": 76134020,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 7210552,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 10202.91,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 1301.9906666666668,
    "characteristics.power.normalized_per_core": 325.4976666666667,
    "characteristics.power.normalized_per_processor": 325.4976666666667,
    "characteristics.scheduled_queries_per_second": 10202.91,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2550.7275,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2550.7275,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 10200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 64,
    "uid": "b049529a54b919c3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 45152078,
    "90.00 percentile latency (ns)": 75121176,
    "95.00 percentile latency (ns)": 85961246,
    "97.00 percentile latency (ns)": 93415000,
    "99.00 percentile latency (ns)": 107657341,
    "99.90 percentile latency (ns)": 133131174,
    "Completed samples per second": 4302.23,
    "Max latency (ns)": 164675061,
    "Mean latency (ns)": 48622273,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4867384,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 4302.49,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 1295.0170000000026,
    "characteristics.power.normalized_per_core": 323.75425000000064,
    "characteristics.power.normalized_per_processor": 323.75425000000064,
    "characteristics.scheduled_queries_per_second": 4302.49,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1075.6225,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1075.6225,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 4300,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 64,
    "uid": "4a75b2c1af48a7a2",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 55570945,
    "90.00 percentile latency (ns)": 74545240,
    "95.00 percentile latency (ns)": 79501281,
    "97.00 percentile latency (ns)": 82634356,
    "99.00 percentile latency (ns)": 88532119,
    "99.90 percentile latency (ns)": 96601744,
    "Completed samples per second": 20791.43,
    "Max latency (ns)": 136206050,
    "Mean latency (ns)": 55644494,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5723507,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 20792.35,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 20792.35,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2599.04375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2599.04375,
    "ck_system": "A100-PCIex8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 20800,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "717b7bc45288cc18",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 57568553,
    "90.00 percentile latency (ns)": 89537514,
    "95.00 percentile latency (ns)": 99391928,
    "97.00 percentile latency (ns)": 105957154,
    "99.00 percentile latency (ns)": 118816222,
    "99.90 percentile latency (ns)": 140868019,
    "Completed samples per second": 9603.49,
    "Max latency (ns)": 174381564,
    "Mean latency (ns)": 59913688,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5355932,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 9604.47,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 9604.47,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1200.55875,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1200.55875,
    "ck_system": "A100-PCIex8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A100-PCIex8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 9600,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "cdc9d307ee782884",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 20549636,
    "90.00 percentile latency (ns)": 26997419,
    "95.00 percentile latency (ns)": 29346066,
    "97.00 percentile latency (ns)": 31041342,
    "99.00 percentile latency (ns)": 35002567,
    "99.90 percentile latency (ns)": 41167038,
    "Completed samples per second": 22953.9,
    "Max latency (ns)": 1004244377,
    "Mean latency (ns)": 21559469,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 12805977,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 22992.32,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 22992.32,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2874.04,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2874.04,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 23000,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "fc23fb338d24d29b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 44775280,
    "90.00 percentile latency (ns)": 48221870,
    "95.00 percentile latency (ns)": 49268751,
    "97.00 percentile latency (ns)": 49957222,
    "99.00 percentile latency (ns)": 51223084,
    "99.90 percentile latency (ns)": 53655726,
    "Completed samples per second": 11187.13,
    "Max latency (ns)": 1005272497,
    "Mean latency (ns)": 44856080,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 34190752,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 11205.87,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 11205.87,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1400.73375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1400.73375,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 11205,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "5dba6244b2845d48",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 47107630,
    "90.00 percentile latency (ns)": 60137285,
    "95.00 percentile latency (ns)": 63771573,
    "97.00 percentile latency (ns)": 66202154,
    "99.00 percentile latency (ns)": 73715099,
    "99.90 percentile latency (ns)": 544298864755,
    "Completed samples per second": 21490.5,
    "Max latency (ns)": 606415168395,
    "Mean latency (ns)": 3026256424,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 6413929,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 21491.71,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 3563.5158415841615,
    "characteristics.power.normalized_per_core": 445.4394801980202,
    "characteristics.power.normalized_per_processor": 445.4394801980202,
    "characteristics.scheduled_queries_per_second": 21491.71,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2686.46375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2686.46375,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 21500,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "702ae2c9ac974a3b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 30761475,
    "90.00 percentile latency (ns)": 43523217,
    "95.00 percentile latency (ns)": 47716513,
    "97.00 percentile latency (ns)": 50835315,
    "99.00 percentile latency (ns)": 63754706,
    "99.90 percentile latency (ns)": 545238876295,
    "Completed samples per second": 10001.9,
    "Max latency (ns)": 606238334331,
    "Mean latency (ns)": 3000090184,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4960507,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 10002.74,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 3506.393729372935,
    "characteristics.power.normalized_per_core": 438.2992161716169,
    "characteristics.power.normalized_per_processor": 438.2992161716169,
    "characteristics.scheduled_queries_per_second": 10002.74,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1250.3425,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1250.3425,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 10000,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "cf4f8533649c3867",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 45531016,
    "90.00 percentile latency (ns)": 58535310,
    "95.00 percentile latency (ns)": 61848399,
    "97.00 percentile latency (ns)": 64119728,
    "99.00 percentile latency (ns)": 71396863,
    "99.90 percentile latency (ns)": 516772526384,
    "Completed samples per second": 7203.19,
    "Max latency (ns)": 604881196440,
    "Mean latency (ns)": 2163143233,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5635146,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 7203.81,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 7203.81,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 900.47625,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 900.47625,
    "ck_system": "A10x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 7200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "14a5e8920925e7bd",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 29100583,
    "90.00 percentile latency (ns)": 41966693,
    "95.00 percentile latency (ns)": 46167680,
    "97.00 percentile latency (ns)": 49149046,
    "99.00 percentile latency (ns)": 57242124,
    "99.90 percentile latency (ns)": 520668868949,
    "Completed samples per second": 3121.14,
    "Max latency (ns)": 604308161482,
    "Mean latency (ns)": 2149042542,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5931628,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 3121.31,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 3121.31,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 390.16375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 390.16375,
    "ck_system": "A10x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 3120,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "fbe2183ce1474198",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 82912054,
    "90.00 percentile latency (ns)": 85184885,
    "95.00 percentile latency (ns)": 93594820,
    "97.00 percentile latency (ns)": 104398848,
    "99.00 percentile latency (ns)": 121986193,
    "99.90 percentile latency (ns)": 146503296,
    "Completed samples per second": 19.54,
    "Max latency (ns)": 214970252,
    "Mean latency (ns)": 84098918,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 74881716,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 19.54,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "N/A",
    "accelerator_memory_configuration": "",
    "accelerator_model_name": "N/A",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 0,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 19.54,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 0.1744642857142857,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 4.885,
    "ck_system": "Triton_CPU_4S_8380Hx1",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "OpenVino 2021.2.200",
    "host_memory_capacity": "1536 GB",
    "host_memory_configuration": "6 slots / 32GB each / 3200 MT/s per socket",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8380H CPU @ 2.90GHz",
    "host_processors_per_node": 4,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "fp32",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 112,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/Triton_CPU_4S_8380Hx1",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5 LTS",
    "other_hardware": "",
    "other_software_stack": "Tensorflow 2.4.0, OpenVino 2021.2.200, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 10833,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "No",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "The original weight filename: bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "CPU Inference on Triton Inference Server",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/Triton_CPU_4S_8380Hx1",
    "system_name": "Supermicro SYS-240P-TNRT (Cooper Lake running Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 19.5,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 112,
    "uid": "9945d3ae24d39b91",
    "use_accelerator": false,
    "weight_data_types": "int8",
    "weight_transformations": "We transfer the weight from int8 datatype in ONNX file to int8 datatype in OpenVino IR file."
  },
  {
    "50.00 percentile latency (ns)": 34853095,
    "90.00 percentile latency (ns)": 37383930,
    "95.00 percentile latency (ns)": 38068381,
    "97.00 percentile latency (ns)": 38518954,
    "99.00 percentile latency (ns)": 39424412,
    "99.90 percentile latency (ns)": 41269634,
    "Completed samples per second": 22091.16,
    "Max latency (ns)": 1004984393,
    "Mean latency (ns)": 34915150,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 27766200,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 22460.98,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 22460.98,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2807.6225,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2807.6225,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 22455,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "ee4cb9ad6b8df84f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 45513854,
    "90.00 percentile latency (ns)": 49051511,
    "95.00 percentile latency (ns)": 50175450,
    "97.00 percentile latency (ns)": 50912198,
    "99.00 percentile latency (ns)": 52464311,
    "99.90 percentile latency (ns)": 59259748,
    "Completed samples per second": 11018.76,
    "Max latency (ns)": 1029674966,
    "Mean latency (ns)": 45693170,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 35290297,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 11207.18,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 11207.18,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1400.8975,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1400.8975,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT_Triton",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 11205,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "e74a8df0960b5c9f",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 53687247,
    "90.00 percentile latency (ns)": 69911934,
    "95.00 percentile latency (ns)": 75133338,
    "97.00 percentile latency (ns)": 78873349,
    "99.00 percentile latency (ns)": 107922953,
    "99.90 percentile latency (ns)": 54134660262,
    "Completed samples per second": 7590.41,
    "Max latency (ns)": 61558069733,
    "Mean latency (ns)": 346375630,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5263471,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 7596.02,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 7596.02,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 379.80100000000004,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 379.80100000000004,
    "ck_system": "T4x20_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 7600,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "224848ac56ed730e",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 56717875,
    "90.00 percentile latency (ns)": 75989055,
    "95.00 percentile latency (ns)": 81407724,
    "97.00 percentile latency (ns)": 85015099,
    "99.00 percentile latency (ns)": 98669088,
    "99.90 percentile latency (ns)": 67685714492,
    "Completed samples per second": 3644.1,
    "Max latency (ns)": 75758550087,
    "Mean latency (ns)": 403849724,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 6120767,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 3646.73,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 3646.73,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 182.3365,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 182.3365,
    "ck_system": "T4x20_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 3650,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "37593adc73e29660",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 59698693,
    "90.00 percentile latency (ns)": 86165096,
    "95.00 percentile latency (ns)": 93583030,
    "97.00 percentile latency (ns)": 98086467,
    "99.00 percentile latency (ns)": 105999420,
    "99.90 percentile latency (ns)": 115708021,
    "Completed samples per second": 5192.92,
    "Max latency (ns)": 125093955,
    "Mean latency (ns)": 61616990,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 3021996,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 5199.74,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 5199.74,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2599.87,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2599.87,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 5200,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "b9db0d8123bcf927",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 49300773,
    "90.00 percentile latency (ns)": 74049569,
    "95.00 percentile latency (ns)": 82949915,
    "97.00 percentile latency (ns)": 89167144,
    "99.00 percentile latency (ns)": 101978789,
    "99.90 percentile latency (ns)": 127092856,
    "Completed samples per second": 2426.95,
    "Max latency (ns)": 144587930,
    "Mean latency (ns)": 52156353,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4383874,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 2427.82,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 2427.82,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1213.91,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1213.91,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 2430,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "70dc46e4b2836cf3",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 64826723,
    "90.00 percentile latency (ns)": 89223947,
    "95.00 percentile latency (ns)": 96236329,
    "97.00 percentile latency (ns)": 101977958,
    "99.00 percentile latency (ns)": 120027716,
    "99.90 percentile latency (ns)": 54201124574,
    "Completed samples per second": 24736.35,
    "Max latency (ns)": 60593440408,
    "Mean latency (ns)": 361058808,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 3713653,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 24757.49,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 24757.49,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 3094.68625,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 3094.68625,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 24750,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "754affbd170a0a68",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 39529665,
    "90.00 percentile latency (ns)": 60082421,
    "95.00 percentile latency (ns)": 66899807,
    "97.00 percentile latency (ns)": 72123423,
    "99.00 percentile latency (ns)": 95957353,
    "99.90 percentile latency (ns)": 54442524388,
    "Completed samples per second": 11496.77,
    "Max latency (ns)": 60478459334,
    "Mean latency (ns)": 336435663,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 5188031,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 11502.44,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 11502.44,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1437.805,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1437.805,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 11500,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "c25a377a2cfda78b",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 61165938,
    "90.00 percentile latency (ns)": 79801384,
    "95.00 percentile latency (ns)": 85224889,
    "97.00 percentile latency (ns)": 88919477,
    "99.00 percentile latency (ns)": 102074844,
    "99.90 percentile latency (ns)": 79833158470,
    "Completed samples per second": 3095.69,
    "Max latency (ns)": 88349116340,
    "Mean latency (ns)": 450118001,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 6050254,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 3097.22,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 3097.22,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 387.1525,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 387.1525,
    "ck_system": "T4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 3100,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "a14a3bac893cc4ac",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 50930530,
    "90.00 percentile latency (ns)": 70672103,
    "95.00 percentile latency (ns)": 76584881,
    "97.00 percentile latency (ns)": 80552829,
    "99.00 percentile latency (ns)": 91814037,
    "99.90 percentile latency (ns)": 172639318170,
    "Completed samples per second": 1418.47,
    "Max latency (ns)": 192436283051,
    "Mean latency (ns)": 876745204,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 6352234,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "BERT SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 1418.73,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 1418.73,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 177.34125,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 177.34125,
    "ck_system": "T4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 1420,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "5f3a7c4126a06e2f",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 38918458,
    "90.00 percentile latency (ns)": 43491239,
    "95.00 percentile latency (ns)": 44853735,
    "97.00 percentile latency (ns)": 45778533,
    "99.00 percentile latency (ns)": 47521716,
    "99.90 percentile latency (ns)": 50886446,
    "Completed samples per second": 6899.96,
    "Max latency (ns)": 1012342421,
    "Mean latency (ns)": 38592788,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 23550722,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 7016.31,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 7016.31,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 350.81550000000004,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 350.81550000000004,
    "ck_system": "T4x20_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT_Triton",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 7020,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "a14441f1a4fb06f3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 38353514,
    "90.00 percentile latency (ns)": 45007623,
    "95.00 percentile latency (ns)": 46957795,
    "97.00 percentile latency (ns)": 48316886,
    "99.00 percentile latency (ns)": 51725707,
    "99.90 percentile latency (ns)": 58518709,
    "Completed samples per second": 3370.31,
    "Max latency (ns)": 62795076,
    "Mean latency (ns)": 37881346,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 20984030,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 3371.97,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 3371.97,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 168.5985,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 168.5985,
    "ck_system": "T4x20_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT_Triton",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 3375,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "5ae7bc1c184cceaf",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 40137343,
    "90.00 percentile latency (ns)": 45326580,
    "95.00 percentile latency (ns)": 46908425,
    "97.00 percentile latency (ns)": 47968913,
    "99.00 percentile latency (ns)": 50087945,
    "99.90 percentile latency (ns)": 54647111,
    "Completed samples per second": 2786.47,
    "Max latency (ns)": 59856139,
    "Mean latency (ns)": 39966626,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 23979126,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 2787.5,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 2787.5,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 348.4375,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 348.4375,
    "ck_system": "T4x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 2790,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "af9cb8205484ca7e",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 39723632,
    "90.00 percentile latency (ns)": 47455898,
    "95.00 percentile latency (ns)": 49869020,
    "97.00 percentile latency (ns)": 51596020,
    "99.00 percentile latency (ns)": 55066142,
    "99.90 percentile latency (ns)": 61362049,
    "Completed samples per second": 1330.55,
    "Max latency (ns)": 100313972,
    "Mean latency (ns)": 39544840,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 20617007,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 1330.8,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 1330.8,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 166.35,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 166.35,
    "ck_system": "T4x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 1332,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 56,
    "uid": "7f24b5ebdb87de25",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 33229834,
    "90.00 percentile latency (ns)": 39334591,
    "95.00 percentile latency (ns)": 40583482,
    "97.00 percentile latency (ns)": 41360235,
    "99.00 percentile latency (ns)": 42723613,
    "99.90 percentile latency (ns)": 45041071,
    "Completed samples per second": 4384.27,
    "Max latency (ns)": 47786681,
    "Mean latency (ns)": 33281319,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 21913713,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 4386.07,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 4386.07,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 2193.035,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 2193.035,
    "ck_system": "A100-PCIex2_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT_Triton",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 4390,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "1a94963c4b668a40",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 68019007,
    "90.00 percentile latency (ns)": 81488722,
    "95.00 percentile latency (ns)": 86053303,
    "97.00 percentile latency (ns)": 89473697,
    "99.00 percentile latency (ns)": 96605250,
    "99.90 percentile latency (ns)": 109939685,
    "Completed samples per second": 2366.84,
    "Max latency (ns)": 122560710,
    "Mean latency (ns)": 68352311,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 42137663,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Scenario": "server",
    "Scheduled samples per second": 2367.87,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.scheduled_queries_per_second": 2367.87,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 1183.935,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 1183.935,
    "ck_system": "A100-PCIex2_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "SQuAD v1.1",
    "dataset_link": "",
    "dim_x_default": "seq_number",
    "dim_y_default": "characteristics.scheduled_queries_per_second",
    "dim_y_maximize": false,
    "division": "closed",
    "formal_model": "bert",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "bert-99.9",
    "input_data_types": "int32",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 270336,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT_Triton",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0, Triton 20.09",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 10833,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 1,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "bert_large_v1_1_fake_quant.onnx",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT_Triton",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 130000000,
    "target_qps": 2370,
    "task": "NLP",
    "task2": "nlp",
    "total_cores": 128,
    "uid": "a655dba4f24938b9",
    "use_accelerator": true,
    "weight_data_types": "fp16",
    "weight_transformations": "quantization, affine fusion"
  }
]
