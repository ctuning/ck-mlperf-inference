[
  {
    "50.00 percentile latency (ns)": 10636639,
    "90.00 percentile latency (ns)": 13252178,
    "95.00 percentile latency (ns)": 14024747,
    "97.00 percentile latency (ns)": 14526524,
    "99.00 percentile latency (ns)": 15558681,
    "99.90 percentile latency (ns)": 21375606,
    "Completed samples per second": 447221.6,
    "Max latency (ns)": 72999225,
    "Mean latency (ns)": 10722560,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 246399,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 447227.74,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 447227.74,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 223613.87,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 223613.87,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "384 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 16,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel Xeon Gold 6226R",
    "host_processors_per_node": 2,
    "host_storage_capacity": "1.92 TB",
    "host_storage_type": "SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 455.45.01, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "Fujitsu",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/Fujitsu",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Fujitsu PRIMERGY RX2540 m5 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 30000000,
    "target_qps": 447178,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 32,
    "uid": "6740289b7ad7f8d9",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 10636639,
    "90.00 percentile latency (ns)": 13252178,
    "95.00 percentile latency (ns)": 14024747,
    "97.00 percentile latency (ns)": 14526524,
    "99.00 percentile latency (ns)": 15558681,
    "99.90 percentile latency (ns)": 21375606,
    "Completed samples per second": 447221.6,
    "Max latency (ns)": 72999225,
    "Mean latency (ns)": 10722560,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 246399,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 447227.74,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe-40GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 447227.74,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 223613.87,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 223613.87,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "384 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 16,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel Xeon Gold 6226R",
    "host_processors_per_node": 2,
    "host_storage_capacity": "1.92 TB",
    "host_storage_type": "SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 455.45.01, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "Fujitsu",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/Fujitsu",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Fujitsu PRIMERGY RX2540 m5 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 30000000,
    "target_qps": 447178,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 32,
    "uid": "ae0a0713fed0840f",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1487494,
    "90.00 percentile latency (ns)": 2869107,
    "95.00 percentile latency (ns)": 3432193,
    "97.00 percentile latency (ns)": 3819890,
    "99.00 percentile latency (ns)": 4569174,
    "99.90 percentile latency (ns)": 5709253,
    "Completed samples per second": 164813.29,
    "Max latency (ns)": 13815552,
    "Mean latency (ns)": 1720502,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 209517,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 164813.71,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 164813.71,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 82406.855,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 82406.855,
    "ck_system": "A10x2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 16,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "host_storage_capacity": "1.92 TB",
    "host_storage_type": "SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/results/A10x2_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 455.45.01, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "Fujitsu",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/Fujitsu",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x2_TRT",
    "system_name": "Fujitsu PRIMERGY GX2460 m1 (2x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 30000000,
    "target_qps": 164832,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 32,
    "uid": "3d4bbea8453617c3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 1487494,
    "90.00 percentile latency (ns)": 2869107,
    "95.00 percentile latency (ns)": 3432193,
    "97.00 percentile latency (ns)": 3819890,
    "99.00 percentile latency (ns)": 4569174,
    "99.90 percentile latency (ns)": 5709253,
    "Completed samples per second": 164813.29,
    "Max latency (ns)": 13815552,
    "Mean latency (ns)": 1720502,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 209517,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Performance constraints satisfied": "Yes",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Scenario": "server",
    "Scheduled samples per second": 164813.71,
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.scheduled_queries_per_second": 164813.71,
    "characteristics.scheduled_queries_per_second.normalized_per_core": 82406.855,
    "characteristics.scheduled_queries_per_second.normalized_per_processor": 82406.855,
    "ck_system": "A10x2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.scheduled_queries_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 16,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7302",
    "host_processors_per_node": 2,
    "host_storage_capacity": "1.92 TB",
    "host_storage_type": "SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 0,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 270336,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/Fujitsu/results/A10x2_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.5",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 455.45.01, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "Fujitsu",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/Fujitsu",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x2_TRT",
    "system_name": "Fujitsu PRIMERGY GX2460 m1 (2x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 30000000,
    "target_qps": 164832,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 32,
    "uid": "43e201527342d086",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  }
]
