[
  {
    "50.00 percentile latency (ns)": 332424145729,
    "90.00 percentile latency (ns)": 598767268210,
    "95.00 percentile latency (ns)": 632057196664,
    "97.00 percentile latency (ns)": 645374995874,
    "99.00 percentile latency (ns)": 658692339179,
    "99.90 percentile latency (ns)": 664686564641,
    "Max latency (ns)": 665351565674,
    "Mean latency (ns)": 14750814281,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10648432,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Samples per second": 785630,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 785630,
    "characteristics.samples_per_second.normalized_per_core": 98203.75,
    "characteristics.samples_per_second.normalized_per_processor": 98203.75,
    "ck_system": "A10x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 522720000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 792000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "31bdacb65e487db6",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 332424145729,
    "90.00 percentile latency (ns)": 598767268210,
    "95.00 percentile latency (ns)": 632057196664,
    "97.00 percentile latency (ns)": 645374995874,
    "99.00 percentile latency (ns)": 658692339179,
    "99.90 percentile latency (ns)": 664686564641,
    "Max latency (ns)": 665351565674,
    "Mean latency (ns)": 14750814281,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 10648432,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Samples per second": 785630,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 785630,
    "characteristics.samples_per_second.normalized_per_core": 98203.75,
    "characteristics.samples_per_second.normalized_per_processor": 98203.75,
    "ck_system": "A10x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 522720000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT_Triton",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 792000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "3a081fcbe98b44a3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 328965676289,
    "90.00 percentile latency (ns)": 590820888404,
    "95.00 percentile latency (ns)": 623485377391,
    "97.00 percentile latency (ns)": 636525035427,
    "99.00 percentile latency (ns)": 649612898577,
    "99.90 percentile latency (ns)": 655488072391,
    "Max latency (ns)": 656135410160,
    "Mean latency (ns)": 58717370642,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2880233029,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 311826,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 311826,
    "characteristics.samples_per_second.normalized_per_core": 311826.0,
    "characteristics.samples_per_second.normalized_per_processor": 311826.0,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 204600000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 310000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "8b4abf4375bd82b6",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 328965676289,
    "90.00 percentile latency (ns)": 590820888404,
    "95.00 percentile latency (ns)": 623485377391,
    "97.00 percentile latency (ns)": 636525035427,
    "99.00 percentile latency (ns)": 649612898577,
    "99.90 percentile latency (ns)": 655488072391,
    "Max latency (ns)": 656135410160,
    "Mean latency (ns)": 58717370642,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2880233029,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 311826,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 311826,
    "characteristics.samples_per_second.normalized_per_core": 311826.0,
    "characteristics.samples_per_second.normalized_per_processor": 311826.0,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 204600000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 310000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "2eb7f0a8d54fe3f3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 332905615027,
    "90.00 percentile latency (ns)": 599636489782,
    "95.00 percentile latency (ns)": 632964928158,
    "97.00 percentile latency (ns)": 646305158068,
    "99.00 percentile latency (ns)": 659640362825,
    "99.90 percentile latency (ns)": 665640901390,
    "Max latency (ns)": 666316778144,
    "Mean latency (ns)": 62572300933,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4463850,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Samples per second": 307061,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 307061,
    "characteristics.samples_per_second.normalized_per_core": 307061.0,
    "characteristics.samples_per_second.normalized_per_processor": 307061.0,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 204600000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 310000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "179bd90f7693bbae",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 332905615027,
    "90.00 percentile latency (ns)": 599636489782,
    "95.00 percentile latency (ns)": 632964928158,
    "97.00 percentile latency (ns)": 646305158068,
    "99.00 percentile latency (ns)": 659640362825,
    "99.90 percentile latency (ns)": 665640901390,
    "Max latency (ns)": 666316778144,
    "Mean latency (ns)": 62572300933,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4463850,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Samples per second": 307061,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 307061,
    "characteristics.samples_per_second.normalized_per_core": 307061.0,
    "characteristics.samples_per_second.normalized_per_processor": 307061.0,
    "ck_system": "DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 204600000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx1_TRT_Triton_datacenter",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 310000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "bb9af71c27d9c3f0",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 354661045085,
    "90.00 percentile latency (ns)": 624920443090,
    "95.00 percentile latency (ns)": 658712499265,
    "97.00 percentile latency (ns)": 672210392071,
    "99.00 percentile latency (ns)": 685706790840,
    "99.90 percentile latency (ns)": 691774009738,
    "Max latency (ns)": 692449514867,
    "Mean latency (ns)": 5301161378,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 17140018716,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 1067510.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 1067510.0,
    "characteristics.samples_per_second.normalized_per_core": 133438.75,
    "characteristics.samples_per_second.normalized_per_processor": 133438.75,
    "ck_system": "A30x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 739200000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 1120000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "d5f1d88ae094ce6b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 354661045085,
    "90.00 percentile latency (ns)": 624920443090,
    "95.00 percentile latency (ns)": 658712499265,
    "97.00 percentile latency (ns)": 672210392071,
    "99.00 percentile latency (ns)": 685706790840,
    "99.90 percentile latency (ns)": 691774009738,
    "Max latency (ns)": 692449514867,
    "Mean latency (ns)": 5301161378,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 17140018716,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 1067510.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 1067510.0,
    "characteristics.samples_per_second.normalized_per_core": 133438.75,
    "characteristics.samples_per_second.normalized_per_processor": 133438.75,
    "ck_system": "A30x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 739200000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 1120000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "b6bc64b80af40dda",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 337836814354,
    "90.00 percentile latency (ns)": 608294741770,
    "95.00 percentile latency (ns)": 642092993465,
    "97.00 percentile latency (ns)": 655617934461,
    "99.00 percentile latency (ns)": 669160734714,
    "99.90 percentile latency (ns)": 675248827978,
    "Max latency (ns)": 675923166836,
    "Mean latency (ns)": 13429036839,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 13780237,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Samples per second": 1093620.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 1093620.0,
    "characteristics.samples_per_second.normalized_per_core": 136702.5,
    "characteristics.samples_per_second.normalized_per_processor": 136702.5,
    "ck_system": "A30x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 739200000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 1120000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "e8670e0fee174ec3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 337836814354,
    "90.00 percentile latency (ns)": 608294741770,
    "95.00 percentile latency (ns)": 642092993465,
    "97.00 percentile latency (ns)": 655617934461,
    "99.00 percentile latency (ns)": 669160734714,
    "99.90 percentile latency (ns)": 675248827978,
    "Max latency (ns)": 675923166836,
    "Mean latency (ns)": 13429036839,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 13780237,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "Triton_Server",
    "Samples per second": 1093620.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "24 GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A30",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 1093620.0,
    "characteristics.samples_per_second.normalized_per_core": 136702.5,
    "characteristics.samples_per_second.normalized_per_processor": 136702.5,
    "ck_system": "A30x8_TRT_Triton",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A30x8_TRT_Triton",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.46, DALI 0.30.0, Triton 21.02",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 739200000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A30x8_TRT_Triton",
    "system_name": "Gigabyte G482-Z54 (8x A30, TensorRT, Triton)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 1120000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "22e7be0d4ac0bafa",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 332694345892,
    "90.00 percentile latency (ns)": 581153923826,
    "95.00 percentile latency (ns)": 612214224015,
    "97.00 percentile latency (ns)": 624666047220,
    "99.00 percentile latency (ns)": 637080742592,
    "99.90 percentile latency (ns)": 642679376775,
    "Max latency (ns)": 643300593019,
    "Mean latency (ns)": 6699927866,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 22805509567,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 2462300.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 2462300.0,
    "characteristics.samples_per_second.normalized_per_core": 307787.5,
    "characteristics.samples_per_second.normalized_per_processor": 307787.5,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1584000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 2400000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "0fe78f42f490af90",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 332694345892,
    "90.00 percentile latency (ns)": 581153923826,
    "95.00 percentile latency (ns)": 612214224015,
    "97.00 percentile latency (ns)": 624666047220,
    "99.00 percentile latency (ns)": 637080742592,
    "99.90 percentile latency (ns)": 642679376775,
    "Max latency (ns)": 643300593019,
    "Mean latency (ns)": 6699927866,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 22805509567,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 2462300.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 2462300.0,
    "characteristics.samples_per_second.normalized_per_core": 307787.5,
    "characteristics.samples_per_second.normalized_per_processor": 307787.5,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1584000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 2400000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "bc5044f219dfe89e",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 308870549741,
    "90.00 percentile latency (ns)": 557037541938,
    "95.00 percentile latency (ns)": 588419036236,
    "97.00 percentile latency (ns)": 601007542283,
    "99.00 percentile latency (ns)": 613549639798,
    "99.90 percentile latency (ns)": 621730655791,
    "Max latency (ns)": 624081950442,
    "Mean latency (ns)": 2358271084,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4217448721,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 1057550.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 1057550.0,
    "characteristics.samples_per_second.normalized_per_core": 264387.5,
    "characteristics.samples_per_second.normalized_per_processor": 264387.5,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 660000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": "1e+06",
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 64,
    "uid": "96a4ba6b9b253ebe",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 308870549741,
    "90.00 percentile latency (ns)": 557037541938,
    "95.00 percentile latency (ns)": 588419036236,
    "97.00 percentile latency (ns)": 601007542283,
    "99.00 percentile latency (ns)": 613549639798,
    "99.90 percentile latency (ns)": 621730655791,
    "Max latency (ns)": 624081950442,
    "Mean latency (ns)": 2358271084,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4217448721,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 1057550.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 1057550.0,
    "characteristics.samples_per_second.normalized_per_core": 264387.5,
    "characteristics.samples_per_second.normalized_per_processor": 264387.5,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 660000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": "1e+06",
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 64,
    "uid": "465abf39f0ee5610",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 362187722442,
    "90.00 percentile latency (ns)": 651438887388,
    "95.00 percentile latency (ns)": 687639277353,
    "97.00 percentile latency (ns)": 702116065424,
    "99.00 percentile latency (ns)": 716596518057,
    "99.90 percentile latency (ns)": 723110373338,
    "Max latency (ns)": 723827274590,
    "Mean latency (ns)": 362178665272,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 610988809,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 36472.8,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 36472.8,
    "characteristics.samples_per_second.normalized_per_core": 36472.8,
    "characteristics.samples_per_second.normalized_per_processor": 36472.8,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 26400000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 40000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "800b4b52334faf8b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 362187722442,
    "90.00 percentile latency (ns)": 651438887388,
    "95.00 percentile latency (ns)": 687639277353,
    "97.00 percentile latency (ns)": 702116065424,
    "99.00 percentile latency (ns)": 716596518057,
    "99.90 percentile latency (ns)": 723110373338,
    "Max latency (ns)": 723827274590,
    "Mean latency (ns)": 362178665272,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 610988809,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 36472.8,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB (1x1g.10gb MIG)",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 1,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 36472.8,
    "characteristics.samples_per_second.normalized_per_core": 36472.8,
    "characteristics.samples_per_second.normalized_per_processor": 36472.8,
    "ck_system": "DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 1,
    "normalize_processors": 1,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 26400000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GB-MIG_1x1g.10gb_TRT_HeteroMultiUse",
    "system_name": "NVIDIA DGX-A100 (1x A100-SXM-80GB-MIG-1x1g.10gb, TensorRT, HeteroMultiUse)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 40000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "ba08dadf79511d2b",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 335465953493,
    "90.00 percentile latency (ns)": 603285042314,
    "95.00 percentile latency (ns)": 636774591443,
    "97.00 percentile latency (ns)": 650171060861,
    "99.00 percentile latency (ns)": 664677053650,
    "99.90 percentile latency (ns)": 674519481508,
    "Max latency (ns)": 677221388118,
    "Mean latency (ns)": 592624941,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4285225558,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 974571,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 1277.8926144756279,
    "characteristics.power.normalized_per_core": 319.47315361890696,
    "characteristics.power.normalized_per_processor": 319.47315361890696,
    "characteristics.samples_per_second": 974571,
    "characteristics.samples_per_second.normalized_per_core": 243642.75,
    "characteristics.samples_per_second.normalized_per_processor": 243642.75,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 660000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": "1e+06",
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 64,
    "uid": "cfed188063a34b7c",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 335465953493,
    "90.00 percentile latency (ns)": 603285042314,
    "95.00 percentile latency (ns)": 636774591443,
    "97.00 percentile latency (ns)": 650171060861,
    "99.00 percentile latency (ns)": 664677053650,
    "99.90 percentile latency (ns)": 674519481508,
    "Max latency (ns)": 677221388118,
    "Mean latency (ns)": 592624941,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 4285225558,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 974571,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 4,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 1277.8926144756279,
    "characteristics.power.normalized_per_core": 319.47315361890696,
    "characteristics.power.normalized_per_processor": 319.47315361890696,
    "characteristics.samples_per_second": 974571,
    "characteristics.samples_per_second.normalized_per_core": 243642.75,
    "characteristics.samples_per_second.normalized_per_processor": 243642.75,
    "ck_system": "DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "512 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 1,
    "host_storage_capacity": "10 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 4,
    "normalize_processors": 4,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 660000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-Station-A100_A100-SXM-80GBx4_TRT_MaxQ",
    "system_name": "NVIDIA DGX Station A100 (4x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": "1e+06",
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 64,
    "uid": "dc4209988ce9aca0",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 384583265090,
    "90.00 percentile latency (ns)": 675777615717,
    "95.00 percentile latency (ns)": 712189793390,
    "97.00 percentile latency (ns)": 726753311739,
    "99.00 percentile latency (ns)": 741316386567,
    "99.90 percentile latency (ns)": 747871359806,
    "Max latency (ns)": 748599357039,
    "Mean latency (ns)": 563925525,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 22507442172,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 2115950.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 3415.354010695183,
    "characteristics.power.normalized_per_core": 426.9192513368979,
    "characteristics.power.normalized_per_processor": 426.9192513368979,
    "characteristics.samples_per_second": 2115950.0,
    "characteristics.samples_per_second.normalized_per_core": 264493.75,
    "characteristics.samples_per_second.normalized_per_processor": 264493.75,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1584000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 2400000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "db7b2169669e4a04",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 384583265090,
    "90.00 percentile latency (ns)": 675777615717,
    "95.00 percentile latency (ns)": 712189793390,
    "97.00 percentile latency (ns)": 726753311739,
    "99.00 percentile latency (ns)": 741316386567,
    "99.90 percentile latency (ns)": 747871359806,
    "Max latency (ns)": 748599357039,
    "Mean latency (ns)": 563925525,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 22507442172,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 2115950.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "80 GB",
    "accelerator_memory_configuration": "HBM2e",
    "accelerator_model_name": "NVIDIA A100-SXM-80GB",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.power": 3415.354010695183,
    "characteristics.power.normalized_per_core": 426.9192513368979,
    "characteristics.power.normalized_per_processor": 426.9192513368979,
    "characteristics.samples_per_second": 2115950.0,
    "characteristics.samples_per_second.normalized_per_core": 264493.75,
    "characteristics.samples_per_second.normalized_per_processor": 264493.75,
    "ck_system": "DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "2 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 1584000000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM-80GBx8_TRT_MaxQ",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM-80GB, MaxQ, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 2400000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "ce429bb664cbc530",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 340033298278,
    "90.00 percentile latency (ns)": 605800760061,
    "95.00 percentile latency (ns)": 639029913724,
    "97.00 percentile latency (ns)": 652317667153,
    "99.00 percentile latency (ns)": 665607160810,
    "99.90 percentile latency (ns)": 675431952182,
    "Max latency (ns)": 676766694363,
    "Mean latency (ns)": 22546370778,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8840204478,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 772378,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 772378,
    "characteristics.samples_per_second.normalized_per_core": 96547.25,
    "characteristics.samples_per_second.normalized_per_processor": 96547.25,
    "ck_system": "A10x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 522720000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 792000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "14670847c0b26ca6",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 340033298278,
    "90.00 percentile latency (ns)": 605800760061,
    "95.00 percentile latency (ns)": 639029913724,
    "97.00 percentile latency (ns)": 652317667153,
    "99.00 percentile latency (ns)": 665607160810,
    "99.90 percentile latency (ns)": 675431952182,
    "Max latency (ns)": 676766694363,
    "Mean latency (ns)": 22546370778,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 8840204478,
    "Min queries satisfied": "Yes",
    "Mode": "PerformanceOnly",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 772378,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA A10",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "boot_firmware_version": "",
    "characteristics.samples_per_second": 772378,
    "characteristics.samples_per_second.normalized_per_core": 96547.25,
    "characteristics.samples_per_second.normalized_per_processor": 96547.25,
    "ck_system": "A10x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "disk_controllers": "",
    "disk_drives": "",
    "division": "closed",
    "filesystem": "",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2.3, CUDA 11.1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "management_firmware_version": "",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 600000,
    "min_query_count": 1,
    "mlperf_version": "v1.0",
    "network_speed_mbit": "",
    "nics_enabled_connected": "",
    "nics_enabled_firmware": "",
    "nics_enabled_os": "",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v1.0/tree/master/closed/NVIDIA/results/A10x8_TRT",
    "number_of_nodes": 1,
    "number_of_type_nics_installed": "",
    "operating_system": "Ubuntu 18.04.4",
    "other_hardware": "",
    "other_software_stack": "TensorRT 7.2.3, CUDA 11.1, cuDNN 8.1.1, Driver 460.32.03, DALI 0.30.0",
    "performance_issue_same": 0,
    "performance_issue_same_index": 0,
    "performance_issue_unique": 0,
    "performance_sample_count": 204800,
    "power_management": "",
    "power_supply_details": "",
    "power_supply_quantity_and_rating_watts": "",
    "print_timestamps": 0,
    "problem": false,
    "qsl_rng_seed": 7322528924094909334,
    "retraining": "N",
    "sample_index_rng_seed": 1570999273408051088,
    "samples_per_query": 522720000,
    "schedule_rng_seed": 3507442325620259414,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "preview",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A10x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x A10, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 792000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "2a7bb9d1d4394cb3",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 34100820843,
    "90.00 percentile latency (ns)": 60710032626,
    "95.00 percentile latency (ns)": 64071400433,
    "97.00 percentile latency (ns)": 65413069997,
    "99.00 percentile latency (ns)": 66750827356,
    "99.90 percentile latency (ns)": 67356150237,
    "Max latency (ns)": 67423238172,
    "Mean latency (ns)": 34208771388,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1365570005,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 665646,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 665646,
    "characteristics.samples_per_second.normalized_per_core": 33282.3,
    "characteristics.samples_per_second.normalized_per_processor": 33282.3,
    "ck_system": "T4x20_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 44880000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 680000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "f47ef9429efad364",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 34100820843,
    "90.00 percentile latency (ns)": 60710032626,
    "95.00 percentile latency (ns)": 64071400433,
    "97.00 percentile latency (ns)": 65413069997,
    "99.00 percentile latency (ns)": 66750827356,
    "99.90 percentile latency (ns)": 67356150237,
    "Max latency (ns)": 67423238172,
    "Mean latency (ns)": 34208771388,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1365570005,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 665646,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 20,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 665646,
    "characteristics.samples_per_second.normalized_per_core": 33282.3,
    "characteristics.samples_per_second.normalized_per_processor": 33282.3,
    "ck_system": "T4x20_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 20,
    "normalize_processors": 20,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x20_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 44880000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x20_TRT",
    "system_name": "Supermicro 6049GP-TRT-OTO-29 (20x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 680000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "b00871af4a9d52e9",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 39334425324,
    "90.00 percentile latency (ns)": 69972684112,
    "95.00 percentile latency (ns)": 73811540741,
    "97.00 percentile latency (ns)": 75348187018,
    "99.00 percentile latency (ns)": 76887578395,
    "99.90 percentile latency (ns)": 77579311062,
    "Max latency (ns)": 77654717858,
    "Mean latency (ns)": 39401593368,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1342955268,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 458955,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 458955,
    "characteristics.samples_per_second.normalized_per_core": 229477.5,
    "characteristics.samples_per_second.normalized_per_processor": 229477.5,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 35640000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 540000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "a972a48ddbb07320",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 39334425324,
    "90.00 percentile latency (ns)": 69972684112,
    "95.00 percentile latency (ns)": 73811540741,
    "97.00 percentile latency (ns)": 75348187018,
    "99.00 percentile latency (ns)": 76887578395,
    "99.90 percentile latency (ns)": 77579311062,
    "Max latency (ns)": 77654717858,
    "Mean latency (ns)": 39401593368,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 1342955268,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 458955,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-PCIe",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 2,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 458955,
    "characteristics.samples_per_second.normalized_per_core": 229477.5,
    "characteristics.samples_per_second.normalized_per_processor": 229477.5,
    "ck_system": "A100-PCIex2_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 2,
    "normalize_processors": 2,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/A100-PCIex2_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 35640000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/A100-PCIex2_TRT",
    "system_name": "Gigabyte G482-Z52 (2x A100-PCIe, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 540000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "e1f346c0a9ee5670",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 34032204969,
    "90.00 percentile latency (ns)": 59771729371,
    "95.00 percentile latency (ns)": 62988013532,
    "97.00 percentile latency (ns)": 64273262138,
    "99.00 percentile latency (ns)": 65560021788,
    "99.90 percentile latency (ns)": 66138842658,
    "Max latency (ns)": 66202788343,
    "Mean latency (ns)": 34063880302,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2007670951,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 2113510.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 2113510.0,
    "characteristics.samples_per_second.normalized_per_core": 264188.75,
    "characteristics.samples_per_second.normalized_per_processor": 264188.75,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 139920000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 2120000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "2d498392a7c63ad4",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 34032204969,
    "90.00 percentile latency (ns)": 59771729371,
    "95.00 percentile latency (ns)": 62988013532,
    "97.00 percentile latency (ns)": 64273262138,
    "99.00 percentile latency (ns)": 65560021788,
    "99.90 percentile latency (ns)": 66138842658,
    "Max latency (ns)": 66202788343,
    "Mean latency (ns)": 34063880302,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 2007670951,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 2113510.0,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "40GB",
    "accelerator_memory_configuration": "HBM2",
    "accelerator_model_name": "NVIDIA A100-SXM4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 2113510.0,
    "characteristics.samples_per_second.normalized_per_core": 264188.75,
    "characteristics.samples_per_second.normalized_per_processor": 264188.75,
    "ck_system": "DGX-A100_A100-SXM4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "1 TB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 64,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "AMD EPYC 7742",
    "host_processors_per_node": 2,
    "host_storage_capacity": "15 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/DGX-A100_A100-SXM4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 139920000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/DGX-A100_A100-SXM4x8_TRT",
    "system_name": "NVIDIA DGX-A100 (8x A100-SXM4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 2120000.0,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 128,
    "uid": "c27f34e11b4247aa",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 33014604822,
    "90.00 percentile latency (ns)": 59291234955,
    "95.00 percentile latency (ns)": 62590934074,
    "97.00 percentile latency (ns)": 63913046482,
    "99.00 percentile latency (ns)": 65233371635,
    "99.90 percentile latency (ns)": 65830039551,
    "Max latency (ns)": 65899193721,
    "Mean latency (ns)": 33107597352,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 603993098,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 272416,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 272416,
    "characteristics.samples_per_second.normalized_per_core": 34052.0,
    "characteristics.samples_per_second.normalized_per_processor": 34052.0,
    "ck_system": "T4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.9,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "dlrm-99.9",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 17952000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 272000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "396e15bfdeb92c52",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  },
  {
    "50.00 percentile latency (ns)": 33014604822,
    "90.00 percentile latency (ns)": 59291234955,
    "95.00 percentile latency (ns)": 62590934074,
    "97.00 percentile latency (ns)": 63913046482,
    "99.00 percentile latency (ns)": 65233371635,
    "99.90 percentile latency (ns)": 65830039551,
    "Max latency (ns)": 65899193721,
    "Mean latency (ns)": 33107597352,
    "Min duration satisfied": "Yes",
    "Min latency (ns)": 603993098,
    "Min queries satisfied": "Yes",
    "Mode": "Performance",
    "Result is": "VALID",
    "SUT name": "DLRM SERVER",
    "Samples per second": 272416,
    "Scenario": "offline",
    "accelerator_frequency": "",
    "accelerator_host_interconnect": "",
    "accelerator_interconnect": "",
    "accelerator_interconnect_topology": "",
    "accelerator_memory_capacity": "16 GB",
    "accelerator_memory_configuration": "GDDR6",
    "accelerator_model_name": "NVIDIA T4",
    "accelerator_on-chip_memories": "",
    "accelerators_per_node": 8,
    "accuracy_log_probability": 0,
    "accuracy_log_rng_seed": 0,
    "accuracy_log_sampling_target": 0,
    "characteristics.samples_per_second": 272416,
    "characteristics.samples_per_second.normalized_per_core": 34052.0,
    "characteristics.samples_per_second.normalized_per_processor": 34052.0,
    "ck_system": "T4x8_TRT",
    "ck_used": false,
    "cooling": "",
    "dataset": "1TB Click Logs",
    "dataset_link": "",
    "dim_x_default": "characteristics.samples_per_second",
    "dim_y_default": "characteristics.AUC",
    "dim_y_maximize": true,
    "division": "closed",
    "formal_model": "dlrm",
    "formal_model_accuracy": 99.0,
    "formal_model_link": "",
    "framework": "TensorRT 7.2, CUDA 11.0 Update 1",
    "host_memory_capacity": "768 GB",
    "host_memory_configuration": "",
    "host_networking": "",
    "host_networking_topology": "",
    "host_processor_caches": "",
    "host_processor_core_count": 28,
    "host_processor_frequency": "",
    "host_processor_interconnect": "",
    "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8280 CPU @ 2.70GHz",
    "host_processors_per_node": 2,
    "host_storage_capacity": "4 TB",
    "host_storage_type": "NVMe SSD",
    "hw_notes": "ECC off",
    "informal_model": "dlrm-99",
    "input_data_types": "int8",
    "max_async_queries": 1,
    "max_duration (ms)": 0,
    "max_query_count": 0,
    "min_duration (ms)": 60000,
    "min_query_count": 1,
    "mlperf_version": "v0.7",
    "normalize_cores": 8,
    "normalize_processors": 8,
    "note_code": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/code",
    "note_details": "https://github.com/mlcommons/inference_results_v0.7/tree/master/closed/NVIDIA/results/T4x8_TRT",
    "number_of_nodes": 1,
    "operating_system": "Ubuntu 18.04.4",
    "other_software_stack": "TensorRT 7.2, CUDA 11.0 Update 1, cuDNN 8.0.2, DALI 0.25.0",
    "performance_issue_same": true,
    "performance_issue_same_index": 0,
    "performance_issue_unique": true,
    "performance_sample_count": 204800,
    "print_timestamps": true,
    "problem": false,
    "qsl_rng_seed": 12786827339337101903,
    "retraining": "N",
    "sample_index_rng_seed": 12640797754436136668,
    "samples_per_query": 17952000,
    "schedule_rng_seed": 3135815929913719677,
    "starting_weights_filename": "tb00_40M.pt",
    "status": "available",
    "submitter": "NVIDIA",
    "submitter_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.submitter/NVIDIA",
    "sw_notes": "",
    "system_link": "https://github.com/ctuning/ck-mlperf-inference/tree/main/bench.mlperf.system/T4x8_TRT",
    "system_name": "Supermicro 4029GP-TRT-OTO-28 (8x T4, TensorRT)",
    "system_type": "datacenter",
    "target_latency (ns)": 0,
    "target_qps": 272000,
    "task": "recommendation",
    "task2": "recommendation",
    "total_cores": 56,
    "uid": "67f893296c0d4bfb",
    "use_accelerator": true,
    "weight_data_types": "int8",
    "weight_transformations": "quantization, affine fusion"
  }
]
